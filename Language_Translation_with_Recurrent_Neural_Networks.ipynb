{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Language Translation with Recurrent Neural Networks.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "be961aa5a37e41d7957c67830c4096cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_54281bbd507a44ddac92d6ae46c4ae39",
              "IPY_MODEL_37dadd0a03f4488bbddd23e393b17684",
              "IPY_MODEL_d70a7220fc464aa09e13f596d861b63c"
            ],
            "layout": "IPY_MODEL_4401795f1ec9493b8a0550bfb7cd8a3e"
          }
        },
        "54281bbd507a44ddac92d6ae46c4ae39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9a7af43a4694a439f2921911a9bd11a",
            "placeholder": "​",
            "style": "IPY_MODEL_bc5919d199504ccd93f80f5631b4b5f8",
            "value": "100%"
          }
        },
        "37dadd0a03f4488bbddd23e393b17684": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60fd2f6f238e4a38a562bdf40c0a6233",
            "max": 1837,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7952b4eadd6c4a929c8aa77c197cc09c",
            "value": 1837
          }
        },
        "d70a7220fc464aa09e13f596d861b63c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86789ef50c9148d89361c61ac902f7cc",
            "placeholder": "​",
            "style": "IPY_MODEL_bd2bdaaa29ba4505883b000a19f13bf5",
            "value": " 1837/1837 [05:29&lt;00:00,  4.64it/s]"
          }
        },
        "4401795f1ec9493b8a0550bfb7cd8a3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9a7af43a4694a439f2921911a9bd11a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc5919d199504ccd93f80f5631b4b5f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60fd2f6f238e4a38a562bdf40c0a6233": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7952b4eadd6c4a929c8aa77c197cc09c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "86789ef50c9148d89361c61ac902f7cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd2bdaaa29ba4505883b000a19f13bf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77d54c6a517b4c7abe2ee25ac1455c3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c796872b221446abfc160d08466a626",
              "IPY_MODEL_a7d5ee3d9f78432b8b8093a9c18561ab",
              "IPY_MODEL_61b1a72d179c487aa28a76f218fb7642"
            ],
            "layout": "IPY_MODEL_2e100923ce444f49ada4321c1f43723a"
          }
        },
        "5c796872b221446abfc160d08466a626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4c6fc0453f9414f9bc78c8ba5bf374a",
            "placeholder": "​",
            "style": "IPY_MODEL_a42bcd8c70714317b49fc076c2eff2f0",
            "value": "  0%"
          }
        },
        "a7d5ee3d9f78432b8b8093a9c18561ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8eb7d07fa7f4dc1a2481144c653e9d7",
            "max": 1837,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8efdc799b1f4f65b205d09195ff0a20",
            "value": 1
          }
        },
        "61b1a72d179c487aa28a76f218fb7642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f18fdc7c6ade414c8d8fa7675f9c480a",
            "placeholder": "​",
            "style": "IPY_MODEL_fb63a4f35c1f4de4b1b8701ea732cf03",
            "value": " 1/1837 [00:00&lt;11:04,  2.76it/s]"
          }
        },
        "2e100923ce444f49ada4321c1f43723a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4c6fc0453f9414f9bc78c8ba5bf374a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a42bcd8c70714317b49fc076c2eff2f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8eb7d07fa7f4dc1a2481144c653e9d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8efdc799b1f4f65b205d09195ff0a20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f18fdc7c6ade414c8d8fa7675f9c480a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb63a4f35c1f4de4b1b8701ea732cf03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "642ed50d610a46518132d1d81d8eff72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d37ef297ff054874a96a8dee6dbb05a1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2fb5c4a8522b4e2a9dc2370469591db1",
              "IPY_MODEL_9e3da17532ef48b7a6e18b4e33dc57fc",
              "IPY_MODEL_e21ea51fdff948f0acd1f8b7ca19a40c"
            ]
          }
        },
        "d37ef297ff054874a96a8dee6dbb05a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2fb5c4a8522b4e2a9dc2370469591db1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4a507a958dd94955a55316c6874590d0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6ebf02ed6cb74d4db2840b782fa08498"
          }
        },
        "9e3da17532ef48b7a6e18b4e33dc57fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f5843682c43a4b478e667c8bef9a967a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 26,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 26,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4f0dd45dfbf34c64aa9c1bfe4003efc5"
          }
        },
        "e21ea51fdff948f0acd1f8b7ca19a40c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2b67a668714840828f5dcbc8bd0f9ca7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 26/26 [00:17&lt;00:00,  1.70it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e27e709353c1498e925f3bc9324ee0bc"
          }
        },
        "4a507a958dd94955a55316c6874590d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6ebf02ed6cb74d4db2840b782fa08498": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5843682c43a4b478e667c8bef9a967a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4f0dd45dfbf34c64aa9c1bfe4003efc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b67a668714840828f5dcbc8bd0f9ca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e27e709353c1498e925f3bc9324ee0bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7604afa227b54cf4aa88115f88992f79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0c973d1a1c474f2788a9c5887530c8eb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7b1d9f9ca96f4dc3bab5cd0d1fe8dd26",
              "IPY_MODEL_52fd6ffcf70f46afb9f0171dff0eeeb9",
              "IPY_MODEL_32dc601f50ed4cd9908d80baac1cdc88"
            ]
          }
        },
        "0c973d1a1c474f2788a9c5887530c8eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b1d9f9ca96f4dc3bab5cd0d1fe8dd26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b97bc1ed31794b8f86da558d38554f4f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_066c3e834b3f47e08d4123091dd4d0bc"
          }
        },
        "52fd6ffcf70f46afb9f0171dff0eeeb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4938814d983a4e47bb26d9e5956c90fc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 26,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 26,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8550e49f730d490db06dbfecbbfaf6d3"
          }
        },
        "32dc601f50ed4cd9908d80baac1cdc88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b7cd55c5b6974d2d80a14edc635bbd3c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 26/26 [00:45&lt;00:00,  1.56s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0415c69f92ac40b6887c850214b631c6"
          }
        },
        "b97bc1ed31794b8f86da558d38554f4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "066c3e834b3f47e08d4123091dd4d0bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4938814d983a4e47bb26d9e5956c90fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8550e49f730d490db06dbfecbbfaf6d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b7cd55c5b6974d2d80a14edc635bbd3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0415c69f92ac40b6887c850214b631c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "28be69da316145cc997fb88669c3835c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_40bd6d2efa8f4be38178c96a11fbb31b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6552a71c617c4bb4afe1c180d35ca6fa",
              "IPY_MODEL_c1de9d199dec4d938f2a9360591d4f3f",
              "IPY_MODEL_b6c6fcba7f964c0aa3e27b53e15b1a99"
            ]
          }
        },
        "40bd6d2efa8f4be38178c96a11fbb31b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6552a71c617c4bb4afe1c180d35ca6fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3a583d6b4de04d74bd42d2a813f32d35",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_39c8b77e176b450a819c476fba6d546c"
          }
        },
        "c1de9d199dec4d938f2a9360591d4f3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_63861a3775a94afbada3983f9ef4820d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 26,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 26,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8317e90ef6f64033bec8ed7df8d232ba"
          }
        },
        "b6c6fcba7f964c0aa3e27b53e15b1a99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b6896318a3b7479cb0d285e38399b001",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 26/26 [00:18&lt;00:00,  1.60it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_92ab7785d9d64895b8c117be09b574b0"
          }
        },
        "3a583d6b4de04d74bd42d2a813f32d35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "39c8b77e176b450a819c476fba6d546c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "63861a3775a94afbada3983f9ef4820d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8317e90ef6f64033bec8ed7df8d232ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b6896318a3b7479cb0d285e38399b001": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "92ab7785d9d64895b8c117be09b574b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "412d4441f0b34d0a982235f958fcdb9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_603e57e04d78422daef459c457838e50",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4d824368aa75494eaca36bda6dcf0a26",
              "IPY_MODEL_5265f531e9f94b5082c9cbd78523b5b1",
              "IPY_MODEL_72a87bd11f734b0ca46aa812f738757d"
            ]
          }
        },
        "603e57e04d78422daef459c457838e50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d824368aa75494eaca36bda6dcf0a26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1e1f41dcd4ad433aabf6eb761916adab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b6b2a422df72417fb823140e4441b98b"
          }
        },
        "5265f531e9f94b5082c9cbd78523b5b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fc0551a31c844b1c8ca389c6211db0a3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 26,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 26,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d48fafabc9c34a1da1e522492bc0797f"
          }
        },
        "72a87bd11f734b0ca46aa812f738757d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_27ba842903f7433badec4c35122cb303",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 26/26 [00:40&lt;00:00,  1.38s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_afed3623abad420fa6e7f7ccbd5325e8"
          }
        },
        "1e1f41dcd4ad433aabf6eb761916adab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b6b2a422df72417fb823140e4441b98b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fc0551a31c844b1c8ca389c6211db0a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d48fafabc9c34a1da1e522492bc0797f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "27ba842903f7433badec4c35122cb303": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "afed3623abad420fa6e7f7ccbd5325e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e16f90ab738749a8b790a3f732afef14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cb80f644cfaf4060abe9f9d2920c2e33",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_24010b3a5aa8424a9b40cac353d973ba",
              "IPY_MODEL_25810c12ce9240c993bc7eddf5eb7e35",
              "IPY_MODEL_080bc356eb1546ae953a0245f7d98c86"
            ]
          }
        },
        "cb80f644cfaf4060abe9f9d2920c2e33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "24010b3a5aa8424a9b40cac353d973ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2bb0c17920f745d3b77a77ae83c3390d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ae4fed0367fd46acb8d06cc4af5045d2"
          }
        },
        "25810c12ce9240c993bc7eddf5eb7e35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2b5d39301aba4340a7d00df5d7934da1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 118,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 118,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1e75b09f82e140acb1f2eeb64362fa65"
          }
        },
        "080bc356eb1546ae953a0245f7d98c86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3e27ef03d617434fb2e2ceb4799cbd3e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 118/118 [00:05&lt;00:00, 22.71it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b0f308da72804ef5b494ba8bd228a61f"
          }
        },
        "2bb0c17920f745d3b77a77ae83c3390d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ae4fed0367fd46acb8d06cc4af5045d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b5d39301aba4340a7d00df5d7934da1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1e75b09f82e140acb1f2eeb64362fa65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3e27ef03d617434fb2e2ceb4799cbd3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b0f308da72804ef5b494ba8bd228a61f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "803732ac85d7459cb094a044a01259ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_444c1ef847c543d38cabc72f6c4c27c8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_beeb94d35cce4b30a6ed8f931e43a192",
              "IPY_MODEL_168aaa61587242f0b9ff7e07f24651bc",
              "IPY_MODEL_e394a56eea074149ac4edc187ab783fb"
            ]
          }
        },
        "444c1ef847c543d38cabc72f6c4c27c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "beeb94d35cce4b30a6ed8f931e43a192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_33dfdb1556bf41e6b0f45fa1d269a6c2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c9fc6df3fc7e4b94a6a99db5dcd9e40f"
          }
        },
        "168aaa61587242f0b9ff7e07f24651bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9d1d02883dcc41d1a0bf8f473676cbb0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 118,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 118,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1e25e0fbc5ca41268f64a0ee4faa579c"
          }
        },
        "e394a56eea074149ac4edc187ab783fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_75668de49e254e39b9056b78ab918cdd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 118/118 [00:15&lt;00:00,  7.02it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef7bf07f4bbc44d09ef2fe822c9f0248"
          }
        },
        "33dfdb1556bf41e6b0f45fa1d269a6c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c9fc6df3fc7e4b94a6a99db5dcd9e40f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9d1d02883dcc41d1a0bf8f473676cbb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1e25e0fbc5ca41268f64a0ee4faa579c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "75668de49e254e39b9056b78ab918cdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef7bf07f4bbc44d09ef2fe822c9f0248": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4f904efb1cab480b9e922063bf139d46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7d2df268c8c4473e92827cd29ab4ffb4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6e5f95171ac44a6ab5e1e6a1230ea30d",
              "IPY_MODEL_f51b5a46f6634cafa6351b9d3e13d2f1",
              "IPY_MODEL_fbd4d6e318a442ecb37ff7d16d997ec5"
            ]
          }
        },
        "7d2df268c8c4473e92827cd29ab4ffb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6e5f95171ac44a6ab5e1e6a1230ea30d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3e3c7ee7e02f4ae190ce37455937c19f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 98%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2784bc53e6c541b0943b6c7b888f9a03"
          }
        },
        "f51b5a46f6634cafa6351b9d3e13d2f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_db794c4312274fc1ad4650aa06dd10b1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 118,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 118,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fcd4971133764a9da013bef5904acfc3"
          }
        },
        "fbd4d6e318a442ecb37ff7d16d997ec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6cd76ad5153b433d97d4aeda33b68980",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 116/118 [00:05&lt;00:00, 22.00it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0c173303ced34a84b18b72b34a6f3da9"
          }
        },
        "3e3c7ee7e02f4ae190ce37455937c19f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2784bc53e6c541b0943b6c7b888f9a03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db794c4312274fc1ad4650aa06dd10b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fcd4971133764a9da013bef5904acfc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6cd76ad5153b433d97d4aeda33b68980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0c173303ced34a84b18b72b34a6f3da9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e68eabc921641a0b68986018bac70e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e808669cbb1f4bf982b57ba75725690c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_69cb79e0ab3e48d599363405bcbf9603",
              "IPY_MODEL_f9d1f8e99f4246c09a6845b01e812ac4",
              "IPY_MODEL_2654f67bc9104f72ad6ba544b7dd6d3b"
            ]
          }
        },
        "e808669cbb1f4bf982b57ba75725690c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "69cb79e0ab3e48d599363405bcbf9603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4f0ed5e9bd044680afb053237174c9b7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a2f7181465cc44fb81eeced33774dc09"
          }
        },
        "f9d1f8e99f4246c09a6845b01e812ac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_110e2f54d63f41389f370b7489d0b8a5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 118,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 118,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_68eaa371cf744e3aa29c3b120c60a18a"
          }
        },
        "2654f67bc9104f72ad6ba544b7dd6d3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4dfcf12d338646f29203cc76ae1e61a4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 118/118 [00:19&lt;00:00,  6.62it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e28bbe0153da47489bc89a2ecc4bab06"
          }
        },
        "4f0ed5e9bd044680afb053237174c9b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a2f7181465cc44fb81eeced33774dc09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "110e2f54d63f41389f370b7489d0b8a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "68eaa371cf744e3aa29c3b120c60a18a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4dfcf12d338646f29203cc76ae1e61a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e28bbe0153da47489bc89a2ecc4bab06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epRaBvj_bapY"
      },
      "source": [
        "# Project 3 (part 2): Language Translation with Recurrent Neural Networks\n",
        "## CS4740/5740 Fall 2021\n",
        "\n",
        "Johann Lee\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fyl3-8TWyR9"
      },
      "source": [
        "## Dataset\n",
        "You are given access to a set of parallel sentences. One sentence is written in modern English (the \"source\") and another is in Shakespearean English (the \"target\"). For this project, given modern English you will need to translate this into Shakespearean English. This is usually called (Neural) Machine Translation. We'll simply refer to it as NMT or Neural Machine Translation in the project.\n",
        "\n",
        "We will minimally preprocess the source/target sentences and handle tokenization in what we release. For this assignment, we do not anticipate any further preprocessing to be done by you. Should you choose to do so, it would be interesting to hear about in the report (along with whether or not it helped performance), but it is not a required aspect of the assignment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARl1pk1PGL2Y",
        "outputId": "d26e6bc6-4509-4e4f-8e63-57d4167f7f47"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "#https://www.digitalocean.com/community/tutorials/how-to-set-up-jupyter-notebook-with-python-3-on-ubuntu-18-04\n",
        "#https://stackoverflow.com/questions/16886179/scp-or-sftp-copy-multiple-files-with-single-command\n",
        "# jupyter notebook --no-browser\n",
        "\n",
        "source_path = os.path.join(os.getcwd(), \"drive\", \"My Drive\", \"sophomore\", \"nlp 4740\", \"project_3\", \"source.txt\") \n",
        "target_path = os.path.join(os.getcwd(), \"drive\", \"My Drive\", \"sophomore\", \"nlp 4740\", \"project_3\", \"target.txt\") \n",
        "test_path = os.path.join(os.getcwd(), \"drive\", \"My Drive\", \"sophomore\", \"nlp 4740\", \"project_3\", \"test.txt\") \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeC3pYiebc6r"
      },
      "source": [
        "## Import libraries and connect to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21NRQju0KuEo",
        "outputId": "aeb19aed-8fd7-4670-f178-922f38ff3f7e"
      },
      "source": [
        "!pip install -U gensim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (4.1.2)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quIJujja-jS2",
        "outputId": "c59584a4-b568-4521-97b0-50ac0df6a3e0"
      },
      "source": [
        "!pip3 install sentencepiece\n",
        "from collections import Counter, namedtuple\n",
        "from itertools import chain\n",
        "import json\n",
        "import math\n",
        "import os\n",
        "from pathlib import Path\n",
        "import random\n",
        "import time\n",
        "from tqdm.notebook import tqdm, trange\n",
        "from typing import List, Tuple, Dict, Set, Union\n",
        "\n",
        "\n",
        "import gensim\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu, SmoothingFunction\n",
        "import numpy as np\n",
        "import sentencepiece as spm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
        "import torch.nn.utils\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
        "\n",
        "\n",
        "from tqdm.notebook import tqdm, trange"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQ2HeOVlKp-4",
        "outputId": "c5c7f7b7-1c7f-411b-b15f-58ccf9baee37"
      },
      "source": [
        "nltk.download(\"punkt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D2uTXRmbn5Q"
      },
      "source": [
        "# Part 1: Recurrent Neural Network\n",
        "\n",
        "Below we define the general problem set up of FFNNs and RNNs.\n",
        "\n",
        "$\\textbf{FFNN.}$ \\\n",
        "$Input: \\text{We have an input vector }\\vec{x} \\in \\mathcal{R}^d$ \\\n",
        "$Model\\text{ }Output: \\text{The model has some intermediate output }\\vec{z} \\in \\mathcal{R}^{\\mid \\mathcal{Y}\\mid}$ \\\n",
        "$Final\\text{ }Output: \\text{ The model outputs a vector } \\vec{y} \\in \\mathcal{R}^{\\mid \\mathcal{Y}\\mid}$ \\\n",
        "$\\vec{y}$ satisfies the constraint of being a probability distribution, i.e. $\\underset{i \\in \\mid \\mathcal{Y} \\mid}{\\sum} \\vec{y}[i] = 1$ and $\\underset{i \\in \\mid \\mathcal{y} \\mid}{min} \\text{ }\\vec{y}[i] \\leq 1$, which is achieved via _Softmax_ applied to $\\vec{z}$.\n",
        "<br></br>\n",
        "$\\textbf{RNN.}$ \\\n",
        "$Input: \\text{The model takes as input a sequence of vectors} \\vec{x}_1,\\vec{x}_2, \\dots, \\vec{x}_k; \\vec{x}_i \\in \\mathcal{R}^d$ \\\n",
        "$Model\\text{ }Output: \\text{The model generates some intermediate sequence output} \\vec{z}_1,\\vec{z}_2, \\dots, \\vec{z}_k; \\vec{z}_i \\in \\mathcal{R}^{h}, \\text{ where h is the hidden state size.}$\n",
        "$Final\\text{ }Output: \\text{The model generates some final sequence output} \\vec{y}_1, \\dots, \\vec{y}_k \\in \\mathcal{R}^{\\mid \\mathcal{Y}\\mid}$ \\\n",
        "$\\vec{y}$ satisfies the constraint of being a probability distribution, i.e. $\\underset{i \\in \\mid \\mathcal{Y} \\mid}{\\sum} \\vec{y}_j[i] = 1$ and $\\underset{i \\in \\mid \\mathcal{y} \\mid}{min} \\text{ }\\vec{y}_j[i] \\geq 0$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4n8IVFtflPQ"
      },
      "source": [
        "Let linear classification vector $\\vec{y}$ be\n",
        "\n",
        "$$\\vec{y}_j = Softmax(W\\vec{z}_j); \\text{ where }W\\in \\mathcal{R}^{\\mid \\mathcal{Y}\\mid \\times h} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfjD4PdHLJeg"
      },
      "source": [
        "Given a sentence in the source language, we look up the word embeddings from an embeddings matrix, yielding $x_1,\\dots, x_n$ ($x_i \\in R^{e}$), where n is the length of the source sentence and e is the embedding size. We feed these embeddings to the bidirectional encoder, yielding hidden states for both the forward (→) and backward (←) RNNs. The forward and backward versions are concatenated to give hidden states $h_i^{enc}$\n",
        "\n",
        "\n",
        "$$h_i^{enc} = [\\overrightarrow{h_i^{enc}}; \\overleftarrow{h_i^{enc}}] \\text{ where }h_i^{enc} \\in R^{2h}, \\overrightarrow{h_i^{enc}}, \\overleftarrow{h_i^{enc}} \\in R^{h}$$\n",
        "\n",
        "\n",
        "We then initialize the decoder’s first hidden state $h_0^{dec}$ with a linear projection of the encoder’s final hidden state\n",
        "\n",
        "$$h_0^{dec} = W_h[\\overrightarrow{h_n^{enc}}; \\overleftarrow{h_0^{enc}}] \\text{ where }h_0^{dec} \\in R^{2h}, W_h \\in R^{h \\times 2h}$$\n",
        "\n",
        "With the decoder initialized, we must now feed it a target sentence. On the $t^{th}$ step, we look up the embedding for the $t^{th}$ word, $y_t \\in R^{e}$. We then concatenate $y_t$ with the combined-output vector $o_{t−1} \\in R^{h}$ from the previous timestep to produce $y_t \\in R^{e+h}$. Note that for the first target (i.e. the start token) $o_0$ is a zero-vector for us (but it can be random or a learned vector as well). We then feed $y_t$ as input to the decoder.\n",
        "\n",
        "$$ h_t^{dec} = Decoder(y_t, h_{t-1}^{dec})\\text{ where }h_{t-1}^{dec} ∈ R^{h}$$\n",
        "\n",
        "We can take the decoder hidden state $h_t^{dec}$ and pass this through a linear layer to obtain an intermediate output $v_t$. This is then passed through an activation function (like tanh) to obtain our combined-output vector $o_t$\n",
        "\n",
        "$$v_t = W_v h_t^{dec} \\text{ where } W_v \\in R^{h \\times h}, v_t \\in R^{h}$$\n",
        "$$o_t = \\tanh{(v_t)} \\text{ where } o_t \\in R^{h}$$\n",
        "\n",
        "Then, we produce a probability distribution $P_t$ over target words at the $t^{th}$ timestep.\n",
        "\n",
        "$$P_t = Softmax(W_{v_{target}} o_t) \\text{ where }P_t \\in R^{V_{target}}, W_{v_{target}}\\in R^{V_{target} \\times h}$$\n",
        "\n",
        "\n",
        "Here, $V_{target}$ is the size of the target vocabulary. Finally, to train the network we then compute the softmax cross entropy loss between $P_t$ and $g_t$, where $g_t$ is the one-hot vector of the target word at timestep t:\n",
        "\n",
        "$$Loss(Model) = CrossEntropy(P_t, g_t)$$\n",
        "\n",
        "Now that we have described the model, we'll implementing it for Modern English to Shakespearean English translation, using **BLEU** (bilingual Evaluation Understudy) as our mtetric. We calculate BLEU by counting matching n-grams in the candidate translation to n-grams in the reference text, where 1-gram or unigram would be each token and a bigram comparison would be each word pair. The comparison is made regardless of word order. BLEU uses N-grams of size 1-4 in its computation.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS1lQBsWWNLc"
      },
      "source": [
        "## 1.1 RNN Implementation\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89rP1JrUyZwZ"
      },
      "source": [
        "### 1.1.1 Data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0NUSRffyCYP"
      },
      "source": [
        "Hypothesis = namedtuple('Hypothesis', ['value', 'score'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vziuNgbJpYvg"
      },
      "source": [
        "def pad_sents(sents, pad_token):\n",
        "    \"\"\" Pad list of sentences according to the longest sentence in the batch.\n",
        "        The paddings should be at the end of each sentence.\n",
        "    :param sents: list of sentences, where each sentence\n",
        "                                    is represented as a list of words\n",
        "    :type sents: list[list[str]]\n",
        "    :param pad_token: padding token\n",
        "    :type pad_token: str\n",
        "    :returns sents_padded: list of sentences where sentences shorter\n",
        "        than the max length sentence are padded out with the pad_token, such that\n",
        "        each sentence in the batch now has equal length.\n",
        "    :rtype: list[list[str]]\n",
        "    \"\"\"\n",
        "    sents_padded = []\n",
        "\n",
        "    max_len = max([len(sent) for sent in sents])\n",
        "    sents_padded = [(sent + ([pad_token] * (max_len - len(sent)))) for sent in sents]\n",
        "\n",
        "    return sents_padded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T77mk7z8pyJw"
      },
      "source": [
        "def read_corpus(file_path, source):\n",
        "    \"\"\" Read file, where each sentence is dilineated by a `\\n`.\n",
        "    :param file_path: path to file containing corpus\n",
        "    :type file_path: str\n",
        "    :param source: \"tgt\" or \"src\" indicating whether text\n",
        "        is of the source language or target language\n",
        "    :type source: str\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    for line in open(file_path):\n",
        "        sent = nltk.word_tokenize(line)\n",
        "        # only append <s> and </s> to the target sentence\n",
        "        if source == 'tgt':\n",
        "            sent = ['<s>'] + sent + ['</s>']\n",
        "        data.append(sent)\n",
        "\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhtfKCGspU1U"
      },
      "source": [
        "class Vocab(object):\n",
        "    \"\"\" Vocabulary, i.e. structure containing either\n",
        "    src or tgt language terms.\n",
        "    \"\"\"\n",
        "    def __init__(self, word2id=None):\n",
        "        \"\"\" Init Vocab Instance.\n",
        "        \n",
        "        :param word2id: dictionary mapping words 2 indices\n",
        "        :type word2id: dict[str, int]\n",
        "        \"\"\"\n",
        "        if word2id:\n",
        "            self.word2id = word2id\n",
        "        else:\n",
        "            self.word2id = dict()\n",
        "            self.word2id['<pad>'] = 0   # Pad Token\n",
        "            self.word2id['<s>'] = 1     # Start Token\n",
        "            self.word2id['</s>'] = 2    # End Token\n",
        "            self.word2id['<unk>'] = 3   # Unknown Token\n",
        "        self.unk_id = self.word2id['<unk>']\n",
        "        self.id2word = {v: k for k, v in self.word2id.items()}\n",
        "\n",
        "    def __getitem__(self, word):\n",
        "        \"\"\" Retrieve word's index. Return the index for the unk\n",
        "        token if the word is out of vocabulary.\n",
        "        \n",
        "        :param word: word to look up\n",
        "        :type word: str\n",
        "        :returns: index of word\n",
        "        :rtype: int\n",
        "        \"\"\"\n",
        "        return self.word2id.get(word, self.unk_id)\n",
        "\n",
        "    def __contains__(self, word):\n",
        "        \"\"\" Check if word is captured by Vocab.\n",
        "        \n",
        "        :param word: word to look up\n",
        "        :type word: str\n",
        "        :returns: whether word is in vocab\n",
        "        :rtype: bool\n",
        "        \"\"\"\n",
        "        return word in self.word2id\n",
        "\n",
        "    def __setitem__(self, key, value):\n",
        "        \"\"\" Raise error, if one tries to edit the Vocab directly.\n",
        "        \"\"\"\n",
        "        raise ValueError('vocabulary is readonly')\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\" Compute number of words in Vocab.\n",
        "        \n",
        "        :returns: number of words in Vocab\n",
        "        :rtype: int\n",
        "        \"\"\"\n",
        "        return len(self.word2id)\n",
        "\n",
        "    def __repr__(self):\n",
        "        \"\"\" Representation of Vocab to be used\n",
        "        when printing the object.\n",
        "        \"\"\"\n",
        "        return 'Vocabulary[size=%d]' % len(self)\n",
        "\n",
        "    def id2word(self, wid):\n",
        "        \"\"\" Return mapping of index to word.\n",
        "        \n",
        "        :param wid: word index\n",
        "        :type wid: int\n",
        "        :returns: word corresponding to index\n",
        "        :rtype: str\n",
        "        \"\"\"\n",
        "        return self.id2word[wid]\n",
        "\n",
        "    def add(self, word):\n",
        "        \"\"\" Add word to Vocab, if it is previously unseen.\n",
        "        \n",
        "        :param word: to add to Vocab\n",
        "        :type word: str\n",
        "        :returns: index that the word has been assigned\n",
        "        :rtype: int\n",
        "        \"\"\"\n",
        "        if word not in self:\n",
        "            wid = self.word2id[word] = len(self)\n",
        "            self.id2word[wid] = word\n",
        "            return wid\n",
        "        else:\n",
        "            return self[word]\n",
        "\n",
        "    def words2indices(self, sents):\n",
        "        \"\"\" Convert list of words or list of sentences of words\n",
        "        into list or list of list of indices.\n",
        "        \n",
        "        :param sents: sentence(s) in words\n",
        "        :type sents: Union[List[str], List[List[str]]]\n",
        "        :returns: sentence(s) in indices\n",
        "        :rtype: Union[List[int], List[List[int]]]\n",
        "        \"\"\"\n",
        "        if type(sents[0]) == list:\n",
        "            return [[self[w] for w in s] for s in sents]\n",
        "        else:\n",
        "            return [self[w] for w in sents]\n",
        "\n",
        "    def indices2words(self, word_ids):\n",
        "        \"\"\" Convert list of indices into words.\n",
        "        \n",
        "        :param word_ids: list of word ids\n",
        "        :type word_ids: List[int]\n",
        "        :returns: list of words\n",
        "        :rtype: List[Str]\n",
        "        \"\"\"\n",
        "        return [self.id2word[w_id] for w_id in word_ids]\n",
        "\n",
        "    def to_input_tensor(self, sents: List[List[str]], device: torch.device) -> torch.Tensor:\n",
        "        \"\"\" Convert list of sentences (words) into tensor with necessary padding for \n",
        "        shorter sentences.\n",
        "        \n",
        "        :param sents: list of sentences (words)\n",
        "        :type sents: List[List[str]]\n",
        "        :param device: Device on which to load the tensor, ie. CPU or GPU\n",
        "        :type device: torch.device\n",
        "        :returns: Sentence tensor of (max_sentence_length, batch_size)\n",
        "        :rtype: torch.Tensor\n",
        "        \"\"\"\n",
        "\n",
        "        word_ids = self.words2indices(sents)\n",
        "        sents_t = pad_sents(word_ids, self['<pad>'])\n",
        "        sents_var = torch.tensor(sents_t, dtype=torch.long, device=device)\n",
        "        return torch.t(sents_var)\n",
        "\n",
        "    @staticmethod\n",
        "    def from_corpus(corpus, size, freq_cutoff=2):\n",
        "        \"\"\" Given a corpus construct a Vocab.\n",
        "        \n",
        "        :param corpus: corpus of text produced by read_corpus function\n",
        "        :type corpus: List[str]\n",
        "        :param size: # of words in vocabulary\n",
        "        :type size: int\n",
        "        :param freq_cutoff: if word occurs n < freq_cutoff times, drop the word\n",
        "        :type freq_cutoff: int\n",
        "        :returns: Vocab instance produced from provided corpus\n",
        "        :rtype: Vocab\n",
        "        \"\"\"\n",
        "        vocab_entry = Vocab()\n",
        "        word_freq = Counter(chain(*corpus))\n",
        "        valid_words = [w for w, v in word_freq.items() if v >= freq_cutoff]\n",
        "        print('number of word types: {}, number of word types w/ frequency >= {}: {}'\n",
        "              .format(len(word_freq), freq_cutoff, len(valid_words)))\n",
        "        top_k_words = sorted(valid_words, key=lambda w: word_freq[w], reverse=True)[:size]\n",
        "        for word in top_k_words:\n",
        "            vocab_entry.add(word)\n",
        "        return vocab_entry\n",
        "    \n",
        "    @staticmethod\n",
        "    def from_subword_list(subword_list):\n",
        "        \"\"\"Given a list of subwords, construct the Vocab.\n",
        "        \n",
        "        :param subword_list: list of subwords in corpus\n",
        "        :type subword_list: List[str]\n",
        "        :returns: Vocab instance produced from provided list\n",
        "        :rtype: Vocab\n",
        "        \"\"\"\n",
        "        vocab_entry = Vocab()\n",
        "        for subword in subword_list:\n",
        "            vocab_entry.add(subword)\n",
        "        return vocab_entry"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2CihDrhyMI_",
        "outputId": "82b268eb-e7f7-470e-8902-7fce7ad07a5b"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "print('initialize source vocabulary ..')\n",
        "src_sents = read_corpus(source_path, \"src\")\n",
        "src = Vocab.from_corpus(src_sents, 20000, 2) # 7098, 9422\n",
        "\n",
        "print('initialize target vocabulary ..')\n",
        "tgt_sents = read_corpus(target_path, \"tgt\")\n",
        "tgt = Vocab.from_corpus(tgt_sents, 20000, 2) # 6893, 10956"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "initialize source vocabulary ..\n",
            "number of word types: 13252, number of word types w/ frequency >= 2: 9167\n",
            "initialize target vocabulary ..\n",
            "number of word types: 15216, number of word types w/ frequency >= 2: 10725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHkmbdw1zZXB"
      },
      "source": [
        "# We explicitly choose to do nothing with respect to embeddings here and the embeddings are learned end-to-end during training in the NMT class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQmyoO0FzzmX"
      },
      "source": [
        "# Split into training and validation data\n",
        "train_data_src, val_data_src, train_data_tgt, val_data_tgt = train_test_split(src_sents, tgt_sents, test_size=0.045922, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0CcUGWHz7WE"
      },
      "source": [
        "train_data = list(zip(train_data_src, train_data_tgt))\n",
        "val_data = list(zip(val_data_src, val_data_tgt))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjWp9yhmyRWR"
      },
      "source": [
        "### 1.1.2 NMT Model Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnwncrLnb6kx"
      },
      "source": [
        "def generate_sent_masks(enc_hiddens: torch.Tensor, source_lengths: List[int], device: torch.device) -> torch.Tensor:\n",
        "    \"\"\" Generate sentence masks for encoder hidden states.\n",
        "\n",
        "    :param enc_hiddens: encodings of shape (b, src_len, 2*h), where b = batch size,\n",
        "        src_len = max source length, h = hidden size.\n",
        "    :type enc_hiddens: torch.Tensor\n",
        "    :param source_lengths: List of actual lengths for each of the sentences in the batch.   \n",
        "    :type source_lengths: List[int]\n",
        "    :param device: Device on which to load the tensor, ie. CPU or GPU\n",
        "    :type device: torch.device\n",
        "    :returns: Tensor of sentence masks of shape (b, src_len),\n",
        "        where src_len = max source length, h = hidden size.\n",
        "    :rtype: torch.Tensor\n",
        "    \"\"\"\n",
        "    enc_masks = torch.zeros(enc_hiddens.size(0), enc_hiddens.size(1), dtype=torch.float)\n",
        "    for e_id, src_len in enumerate(source_lengths):\n",
        "        enc_masks[e_id, src_len:] = 1\n",
        "    return enc_masks.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EApec5FFcNsY"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, embed_size, hidden_size, source_embeddings):\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embed_size = embed_size\n",
        "        self.embedding = source_embeddings\n",
        "        ###     self.encoder (Bidirectional RNN with bias)\n",
        "        ###     self.h_projection (Linear Layer with no bias), called W_{h} above.\n",
        "        # self.n, self.e = self.embedding.size() \n",
        "        self.encoder = torch.nn.LSTM(input_size=embed_size, hidden_size=hidden_size, num_layers=1, bidirectional=True)\n",
        "        # encoder takes embeddings x1,...xn in R^e, therefore input size is embed_size\n",
        "        self.h_projection = torch.nn.Linear(in_features=2*hidden_size, out_features=hidden_size, bias=False)\n",
        "        self.c_projection = torch.nn.Linear(in_features= 2*hidden_size, out_features = hidden_size, bias=False)\n",
        "\n",
        "        \n",
        "    \n",
        "    def forward(self, source_padded: torch.Tensor, source_lengths: List[int]) -> Tuple[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        enc_hiddens, dec_init_state = None, None\n",
        "\n",
        "        ###     1. Construct Tensor `X` of source sentences with shape (src_len, b, e) using the source model embeddings.\n",
        "        ###         src_len = maximum source sentence length, b = batch size, e = embedding size.\n",
        "        ###     2. Compute `enc_hiddens`, `last_hidden` by applying the encoder to `X`.\n",
        "        ###     3. Compute `dec_init_state` = init_decoder_hidden:\n",
        "        ###         - `init_decoder_hidden`:\n",
        "        ###             `last_hidden` is a tensor shape (2, b, h). The first dimension corresponds to forward and backwards.\n",
        "        ###             Concatenate the forward and backward tensors to obtain a tensor shape (b, 2*h).\n",
        "        ###             Apply the h_projection layer to this in order to compute init_decoder_hidden.\n",
        "        ###             This is h_0^{dec} in above in the writeup. Here b = batch size, h = hidden size\n",
        "       \n",
        "        # 1\n",
        "        X = self.embedding(source_padded)\n",
        "        # 2\n",
        "        X = torch.nn.utils.rnn.pack_padded_sequence(X, source_lengths) # b batches of size n\n",
        "        enc_hiddens, (last_hidden, final_cell_state) = self.encoder(X)\n",
        "        enc_hiddens, len = torch.nn.utils.rnn.pad_packed_sequence(X, batch_first = False)\n",
        "        enc_hiddens = torch.permute(enc_hiddens, (1, 0, 2)) # (src_len, b, h*2) -> (b, src_len, h*2)        \n",
        "        # 3\n",
        "        # dec_init_state = torch.cat(last_hidden[0], last_hidden[1]) # concat forward =and backwards of last hidden (2, b, h) to get (b, 2*h)\n",
        "        # dec_init_state = last_hidden.squeeze(0)\n",
        "        # print(last_hidden.shape) # 2, 16, 512\n",
        "        dec_init_state = torch.cat([last_hidden[i] for i in range(last_hidden.size(0))], -1) # concat forward =and backwards of last hidden (2, b, h) to get (b, 2*h)\n",
        "        dec_init_hidden = torch.cat([final_cell_state[i] for i in range(final_cell_state.size(0))], -1)\n",
        "        # print(dec_init_state.shape) # 16, 1024\n",
        "        init_decoder_hidden = self.h_projection(dec_init_state)\n",
        "        init_decoder_cell = self.c_projection(dec_init_hidden)\n",
        "        \n",
        "        dec_init_state = (init_decoder_hidden, init_decoder_cell)\n",
        "\n",
        "        return enc_hiddens, dec_init_state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zj-HTuLCcWum"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, embed_size, hidden_size, target_embedding, device):\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.device = device\n",
        "        self.embedding = target_embedding\n",
        "        output_vocab_size = self.embedding.weight.size(0)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "        ###     self.decoder (RNN Cell with bias)\n",
        "        ###     self.combined_output_projection (Linear Layer with no bias), called W_{v} above.\n",
        "        ###     self.target_vocab_projection (Linear Layer with no bias), called W_{vocab} above.\n",
        "        \n",
        "        self.decoder = torch.nn.LSTMCell(input_size=embed_size+hidden_size, hidden_size=hidden_size, bias=True)\n",
        "        self.combined_output_projection = torch.nn.Linear(in_features=hidden_size, out_features=hidden_size, bias=False) # Wv in Rhxh\n",
        "        self.target_vocab_projection = torch.nn.Linear(in_features=hidden_size, out_features=output_vocab_size, bias=False) # Wtraget in vtarget x h\n",
        "\n",
        "    \n",
        "    def forward(self, enc_hiddens: torch.Tensor,\n",
        "                dec_init_state: torch.Tensor, target_padded: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        # Chop of the <END> token for max length sentences.\n",
        "        target_padded = target_padded[:-1]\n",
        "\n",
        "        dec_state = dec_init_state\n",
        "\n",
        "        # Initialize previous combined output vector o_{t-1} as zero\n",
        "        batch_size = enc_hiddens.size(0)\n",
        "        o_prev = torch.zeros(batch_size, self.hidden_size, device=self.device)\n",
        "\n",
        "        # Initialize a list we will use to collect the combined output o_t on each step\n",
        "        combined_outputs = []\n",
        "\n",
        "        ###     1. Construct tensor `Y` of target sentences with shape (tgt_len, b, e) using the target model embeddings.\n",
        "        ###         where tgt_len = maximum target sentence length, b = batch size, e = embedding size.\n",
        "        ###     2. Use the torch.split function to iterate over the time dimension of Y.\n",
        "        ###         Within the loop, this will give you Y_t of shape (1, b, e) where b = batch size, e = embedding size.\n",
        "        ###             - Squeeze Y_t into a tensor of dimension (b, e). \n",
        "        ###             - Construct Ybar_t by concatenating Y_t with o_prev on their last dimension\n",
        "        ###             - Use the step function to compute the the Decoder's next (cell, state) values\n",
        "        ###               as well as the new combined output o_t.\n",
        "        ###             - Append o_t to combined_outputs\n",
        "        ###             - Update o_prev to the new o_t.\n",
        "        ###     3. Use torch.stack to convert combined_outputs from a list length tgt_len of\n",
        "        ###         tensors shape (b, h), to a single tensor shape (tgt_len, b, h)\n",
        "        ###         where tgt_len = maximum target sentence length, b = batch size, h = hidden size.\n",
        "\n",
        "        # dim is hidden + encoding, encoding is teacher forcing, oprev is prev hidden\n",
        "\n",
        "        #1\n",
        "        Y = self.embedding(target_padded)\n",
        "        # print(Y.shape)\n",
        "\n",
        "        #2\n",
        "        for Y_t in torch.split(Y, 1): # https://edstem.org/us/courses/12801/discussion/861579 ?\n",
        "          # print(\"Y_t shape\", Y_t.shape)\n",
        "          Y_t = torch.squeeze(Y_t)\n",
        "          # print(Y_t.shape)\n",
        "          # print(\"oprev\",o_prev.shape, \" y_t\",Y_t.shape)\n",
        "          # print(Y_t.shape)\n",
        "          Ybar_t = torch.cat((Y_t, o_prev), dim=-1)\n",
        "          # print(\"ybart shaoe\",Ybar_t.shape)\n",
        "          # print(\"got here 1\")\n",
        "          dec_state, o_t = self.step(Ybar_t, dec_state, enc_hiddens) #tdodo\n",
        "          # print(\"got here\")\n",
        "          combined_outputs.append(o_t)\n",
        "          o_prev = o_t\n",
        "          \n",
        "        #3\n",
        "        combined_outputs = torch.stack(combined_outputs)\n",
        "\n",
        "        return combined_outputs\n",
        "    \n",
        "    def step(self, Ybar_t: torch.Tensor,\n",
        "            dec_state: Tuple[torch.Tensor, torch.Tensor],\n",
        "            enc_hiddens: torch.Tensor) -> Tuple[Tuple, torch.Tensor, torch.Tensor]:\n",
        "        \"\"\" Compute one forward step of the LSTM decoder, including the attention computation.\n",
        "\n",
        "        :param Ybar_t: Concatenated Tensor of [Y_t o_prev], with shape (b, e + h). The input for the decoder,\n",
        "                                where b = batch size, e = embedding size, h = hidden size.\n",
        "        :type Ybar_t: torch.Tensor\n",
        "        :param dec_state: Tensors with shape (b, h), where b = batch size, h = hidden size.\n",
        "                Tensor is decoder's prev hidden state\n",
        "        :type dec_state: torch.Tensor\n",
        "        :param enc_hiddens: Encoder hidden states Tensor, with shape (b, src_len, h * 2), where b = batch size,\n",
        "                                    src_len = maximum source length, h = hidden size.\n",
        "        :type enc_hiddens: torch.Tensor\n",
        "\n",
        "        :returns dec_state: Tensors with shape (b, h), where b = batch size, h = hidden size.\n",
        "                Tensor is decoder's new hidden state. For an LSTM, this should be a tuple\n",
        "                of the hidden state and cell state.\n",
        "        returns combined_output: Combined output Tensor at timestep t, shape (b, h), where b = batch size, h = hidden size.\n",
        "        \"\"\"\n",
        "\n",
        "        combined_output = None\n",
        "\n",
        "        ###     1. Apply the decoder to `Ybar_t` and `dec_state` to obtain the new dec_state.\n",
        "        ###     2. Rename dec_state to dec_hidden\n",
        "        # print(Ybar_t.shape, dec_state.shape)\n",
        "        # print(\"get\")\n",
        "        # print(Ybar_t.shape)\n",
        "        # print(dec_state.shape)\n",
        "        dec_state = self.decoder(Ybar_t, dec_state)\n",
        "        # print(\"goot\")\n",
        "        dec_hidden, dec_cell = dec_state\n",
        "\n",
        "        ###     1. Apply the combined output projection layer to h^dec_t to compute tensor V_t\n",
        "        ###     2. Compute tensor O_t by applying the Tanh function.\n",
        "        V_t = self.combined_output_projection(dec_hidden)\n",
        "        O_t = torch.tanh(V_t)\n",
        "\n",
        "        combined_output = O_t\n",
        "        return dec_state, combined_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtWqP3WNcYH3"
      },
      "source": [
        "class NMT(nn.Module):\n",
        "    \"\"\" Simple Neural Machine Translation Model:\n",
        "        - Bidrectional RNN Encoder\n",
        "        - Unidirection RNN Decoder\n",
        "    \"\"\"\n",
        "    def __init__(self, embed_size, hidden_size, src_vocab, tgt_vocab, dropout_rate, device=torch.device(\"cpu\"), pretrained_source=None,pretrained_target=None,):\n",
        "        \"\"\" Init NMT Model.\n",
        "\n",
        "        :param embed_size: Embedding size (dimensionality)\n",
        "        :type embed_size: int\n",
        "        :param hidden_size: Hidden Size, the size of hidden states (dimensionality)\n",
        "        :type hidden_size: int\n",
        "        :param src_vocab: Vocabulary object containing src language\n",
        "        :type src_vocab: Vocab\n",
        "        :param tgt_vocab: Vocabulary object containing tgt language\n",
        "        :type tgt_vocab: Vocab\n",
        "        :param device: torch device to put all modules on\n",
        "        :type device: torch.device\n",
        "        :param pretrained_source: Matrix of pre-trained source word embeddings\n",
        "        :type pretrained_source: Optional[torch.Tensor]\n",
        "        :param pretrained_target: Matrix of pre-trained target word embeddings\n",
        "        :type pretrained_target: Optional[torch.Tensor]\n",
        "        \"\"\"\n",
        "        super(NMT, self).__init__()\n",
        "        self.device=device\n",
        "        self.embed_size = embed_size\n",
        "        self.src_vocab = src_vocab\n",
        "        self.tgt_vocab = tgt_vocab\n",
        "        src_pad_token_idx = src_vocab['<pad>']\n",
        "        tgt_pad_token_idx = tgt_vocab['<pad>']\n",
        "        self.source_embedding = nn.Embedding(len(src_vocab), embed_size, padding_idx=src_pad_token_idx)\n",
        "        self.target_embedding = nn.Embedding(len(tgt_vocab), embed_size, padding_idx=tgt_pad_token_idx)\n",
        "        self.dropout_rate = 0\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            if pretrained_source is not None:\n",
        "                self.source_embedding.weight.data = pretrained_source\n",
        "                # TODO: Decide if we want the embeddings to update as we train\n",
        "                self.source_embedding.weight.requires_grad = False\n",
        "        \n",
        "            if pretrained_target is not None:\n",
        "                self.target_embedding.weight.data = pretrained_target\n",
        "                # TODO: Decide if we want the embeddings to update as we train\n",
        "                self.target_embedding.weight.requires_grad = False\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        # self.dropout_rate = dropout_rate\n",
        "\n",
        "        self.encoder = Encoder(\n",
        "            embed_size=embed_size,\n",
        "            hidden_size=hidden_size,\n",
        "            source_embeddings=self.source_embedding,\n",
        "        )\n",
        "        self.decoder = Decoder(\n",
        "            embed_size=embed_size,\n",
        "            hidden_size=hidden_size,\n",
        "            target_embedding=self.target_embedding,\n",
        "            # dropout_rate=dropout_rate,\n",
        "            device=self.device,\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, source: List[List[str]], target: List[List[str]]) -> torch.Tensor:\n",
        "        \"\"\" Take a mini-batch of source and target sentences, compute the log-likelihood of\n",
        "        target sentences under the language models learned by the NMT system.\n",
        "\n",
        "        :param source: list of source sentence tokens\n",
        "        :type source: List[List[str]]\n",
        "        :param target: list of target sentence tokens, wrapped by `<s>` and `</s>`\n",
        "        :type target: List[List[str]]\n",
        "        :returns scores: a variable/tensor of shape (b, ) representing the\n",
        "                                    log-likelihood of generating the gold-standard target sentence for\n",
        "                                    each example in the input batch. Here b = batch size.\n",
        "        :rtype: torch.Tensor\n",
        "        \"\"\"\n",
        "        # Compute sentence lengths\n",
        "        source_lengths = [len(s) for s in source]\n",
        "\n",
        "        # Convert list of lists into tensors\n",
        "        source_padded = self.src_vocab.to_input_tensor(source, device=self.device)   # Tensor: (src_len, b)\n",
        "        target_padded = self.tgt_vocab.to_input_tensor(target, device=self.device)   # Tensor: (tgt_len, b)\n",
        "        \n",
        "        ###     1. Apply the encoder to `source_padded` by calling `self.encode()`\n",
        "        ###     2. Generate sentence masks for `source_padded` by calling `self.generate_sent_masks()`\n",
        "        ###     3. Apply the decoder to compute combined-output by calling `self.decode()`\n",
        "        ###     4. Compute log probability distribution over the target vocabulary using the\n",
        "        ###        combined_outputs returned by the `self.decode()` function.\n",
        "\n",
        "        enc_hiddens, dec_init_state = self.encode(source_padded, source_lengths)\n",
        "        enc_masks = generate_sent_masks(enc_hiddens, source_lengths, self.device)\n",
        "        combined_outputs = self.decode(enc_hiddens, dec_init_state, target_padded)\n",
        "        P = F.log_softmax(self.decoder.target_vocab_projection(combined_outputs), dim=-1)\n",
        "\n",
        "        # Zero out, probabilities for which we have nothing in the target text\n",
        "        target_masks = (target_padded != self.tgt_vocab['<pad>']).float()\n",
        "        \n",
        "        # Compute log probability of generating true target words\n",
        "        target_gold_words_log_prob = torch.gather(P, index=target_padded[1:].unsqueeze(-1), dim=-1).squeeze(-1) * target_masks[1:]\n",
        "        scores = target_gold_words_log_prob.sum(dim=0)\n",
        "        return scores\n",
        "\n",
        "\n",
        "    def encode(self, source_padded: torch.Tensor, source_lengths: List[int]) -> Tuple[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n",
        "        \"\"\" Apply the encoder to source sentences to obtain encoder hidden states.\n",
        "            Additionally, take the final states of the encoder and project them to obtain initial states for decoder.\n",
        "\n",
        "        :param source_padded: Tensor of padded source sentences with shape (src_len, b), where\n",
        "            b = batch_size, src_len = maximum source sentence length. Note that these have\n",
        "            already been sorted in order of longest to shortest sentence.\n",
        "        :type source_padded: torch.Tensor\n",
        "        :param source_lengths: List of actual lengths for each of the source sentences in the batch\n",
        "        :type source_lengths: List[int]\n",
        "        :returns: Tuple of two items. The first is Tensor of hidden units with shape (b, src_len, h*2),\n",
        "            where b = batch size, src_len = maximum source sentence length, h = hidden size. The second is\n",
        "            Tuple of tensors representing the decoder's initial hidden state and cell.\n",
        "        :rtype: Tuple[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]\n",
        "        \"\"\"\n",
        "        return self.encoder(source_padded, source_lengths)\n",
        "\n",
        "\n",
        "    def decode(self, enc_hiddens: torch.Tensor,\n",
        "                dec_init_state: torch.Tensor, target_padded: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Compute combined output vectors for a batch.\n",
        "\n",
        "        :param enc_hiddens (Tensor): Hidden states (b, src_len, h*2), where\n",
        "                                     b = batch size, src_len = maximum source sentence length, h = hidden size.\n",
        "        :param dec_init_state (tuple(Tensor, Tensor)): Initial state and cell for decoder\n",
        "        :param target_padded: Gold-standard padded target sentences (tgt_len, b), where\n",
        "                                       tgt_len = maximum target sentence length, b = batch size. \n",
        "\n",
        "        :returns combined_outputs: combined output tensor  (tgt_len, b,  h), where\n",
        "                                    tgt_len = maximum target sentence length, b = batch_size,  h = hidden size\n",
        "        :rtype: torch.Tensor\n",
        "        \"\"\"\n",
        "        return self.decoder(enc_hiddens, dec_init_state, target_padded)\n",
        "\n",
        "    def beam_search(self, src_sent: List[str], beam_size: int=5, max_decoding_time_step: int=70) -> List[Hypothesis]:\n",
        "        \"\"\" Given a single source sentence, perform beam search, yielding translations in the target language.\n",
        "        :param src_sent: a single source sentence (words)\n",
        "        :type src_sent: List[str]\n",
        "        :param beam_size: beam size\n",
        "        :type beam_size: int\n",
        "        :param max_decoding_time_step: maximum number of time steps to unroll the decoding RNN\n",
        "        :type max_decoding_time_step: int\n",
        "        :returns hypotheses: a list of hypothesis, each hypothesis has two fields:\n",
        "                value: List[str]: the decoded target sentence, represented as a list of words\n",
        "                score: float: the log-likelihood of the target sentence\n",
        "        :rtype: List[Hypothesis]\n",
        "        \"\"\"\n",
        "        src_sents_var = self.src_vocab.to_input_tensor([src_sent], self.device)\n",
        "\n",
        "        src_encodings, dec_init_vec = self.encode(src_sents_var, [len(src_sent)])\n",
        "\n",
        "        h_tm1 = dec_init_vec\n",
        "        att_tm1 = torch.zeros(1, self.hidden_size, device=self.device)\n",
        "\n",
        "        eos_id = self.tgt_vocab['</s>']\n",
        "\n",
        "        hypotheses = [['<s>']]\n",
        "        hyp_scores = torch.zeros(len(hypotheses), dtype=torch.float, device=self.device)\n",
        "        completed_hypotheses = []\n",
        "\n",
        "        t = 0\n",
        "        while len(completed_hypotheses) < beam_size and t < max_decoding_time_step:\n",
        "            t += 1\n",
        "            hyp_num = len(hypotheses)\n",
        "\n",
        "            exp_src_encodings = src_encodings.expand(hyp_num,\n",
        "                                                     src_encodings.size(1),\n",
        "                                                     src_encodings.size(2))\n",
        "\n",
        "            y_tm1 = torch.tensor([self.tgt_vocab[hyp[-1]] for hyp in hypotheses], dtype=torch.long, device=self.device)\n",
        "            y_t_embed = self.target_embedding(y_tm1)\n",
        "\n",
        "            x = torch.cat([y_t_embed, att_tm1], dim=-1)\n",
        "\n",
        "            h_t, att_t = self.decoder.step(x, h_tm1, exp_src_encodings)\n",
        "          \n",
        "            h_t, c_t = h_t\n",
        "\n",
        "            # log probabilities over target words\n",
        "            log_p_t = F.log_softmax(self.decoder.target_vocab_projection(att_t), dim=-1)\n",
        "\n",
        "            live_hyp_num = beam_size - len(completed_hypotheses)\n",
        "            contiuating_hyp_scores = (hyp_scores.unsqueeze(1).expand_as(log_p_t) + log_p_t).view(-1)\n",
        "            top_cand_hyp_scores, top_cand_hyp_pos = torch.topk(contiuating_hyp_scores, k=live_hyp_num)\n",
        "\n",
        "            prev_hyp_ids = torch.div(top_cand_hyp_pos, len(self.tgt_vocab), rounding_mode='floor')\n",
        "            hyp_word_ids = top_cand_hyp_pos % len(self.tgt_vocab)\n",
        "\n",
        "            new_hypotheses = []\n",
        "            live_hyp_ids = []\n",
        "            new_hyp_scores = []\n",
        "\n",
        "            for prev_hyp_id, hyp_word_id, cand_new_hyp_score in zip(prev_hyp_ids, hyp_word_ids, top_cand_hyp_scores):\n",
        "                prev_hyp_id = prev_hyp_id.item()\n",
        "                hyp_word_id = hyp_word_id.item()\n",
        "                cand_new_hyp_score = cand_new_hyp_score.item()\n",
        "\n",
        "                hyp_word = self.tgt_vocab.id2word[hyp_word_id]\n",
        "                new_hyp_sent = hypotheses[prev_hyp_id] + [hyp_word]\n",
        "                if hyp_word == '</s>':\n",
        "                    completed_hypotheses.append(Hypothesis(value=new_hyp_sent[1:-1],\n",
        "                                                           score=cand_new_hyp_score))\n",
        "                else:\n",
        "                    new_hypotheses.append(new_hyp_sent)\n",
        "                    live_hyp_ids.append(prev_hyp_id)\n",
        "                    new_hyp_scores.append(cand_new_hyp_score)\n",
        "\n",
        "            if len(completed_hypotheses) == beam_size:\n",
        "                break\n",
        "\n",
        "            live_hyp_ids = torch.tensor(live_hyp_ids, dtype=torch.long, device=self.device)\n",
        "\n",
        "            h_tm1 = h_t[live_hyp_ids], c_t[live_hyp_ids]\n",
        "            att_tm1 = att_t[live_hyp_ids]\n",
        "\n",
        "            hypotheses = new_hypotheses\n",
        "            hyp_scores = torch.tensor(new_hyp_scores, dtype=torch.float, device=self.device)\n",
        "\n",
        "        if len(completed_hypotheses) == 0:\n",
        "            completed_hypotheses.append(Hypothesis(value=hypotheses[0][1:],\n",
        "                                                   score=hyp_scores[0].item()))\n",
        "\n",
        "        completed_hypotheses.sort(key=lambda hyp: hyp.score, reverse=True)\n",
        "\n",
        "        return completed_hypotheses\n",
        "\n",
        "\n",
        "    def greedy(self, src_sent: List[str], max_decoding_time_step: int=70) -> List[Hypothesis]:\n",
        "        return self.beam_search(src_sent, beam_size=1, max_decoding_time_step=max_decoding_time_step)\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def load(model_path: str):\n",
        "        \"\"\" Load the model from a file.\n",
        "        @param model_path (str): path to model\n",
        "        \"\"\"\n",
        "        params = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
        "        args = params['args']\n",
        "        model = NMT(\n",
        "            src_vocab=params['vocab']['source'],\n",
        "            tgt_vocab=params['vocab']['target'],\n",
        "            **args\n",
        "        )\n",
        "        model.load_state_dict(params['state_dict'])\n",
        "\n",
        "        return model\n",
        "\n",
        "    def save(self, path: str):\n",
        "        \"\"\" Save the model to a file.\n",
        "        @param path (str): path to the model\n",
        "        \"\"\"\n",
        "        print('save model parameters to [%s]' % path, file=sys.stderr)\n",
        "\n",
        "        params = {\n",
        "            'args': dict(embed_size=self.embed_size, hidden_size=self.hidden_size, dropout_rate=self.dropout_rate),\n",
        "            'vocab': dict(source=self.src_vocab, target=self.tgt_vocab),\n",
        "            'state_dict': self.state_dict()\n",
        "        }\n",
        "\n",
        "        torch.save(params, path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNAHNVKnniOi"
      },
      "source": [
        "def batch_iter(data, batch_size, shuffle=False):\n",
        "    \"\"\" Yield batches of source and target sentences reverse sorted by length (largest to smallest).\n",
        "    :param data: list of tuples containing source and target sentence. ie.\n",
        "        (list of (src_sent, tgt_sent))\n",
        "    :type data: List[Tuple[List[str], List[str]]]\n",
        "    :param batch_size: batch size\n",
        "    :type batch_size: int\n",
        "    :param shuffle: whether to randomly shuffle the dataset\n",
        "    :type shuffle: boolean\n",
        "    \"\"\"\n",
        "    batch_num = math.ceil(len(data) / batch_size)\n",
        "    index_array = list(range(len(data)))\n",
        "\n",
        "    if shuffle:\n",
        "        np.random.shuffle(index_array)\n",
        "\n",
        "    for i in range(batch_num):\n",
        "        indices = index_array[i * batch_size: (i + 1) * batch_size]\n",
        "        examples = [data[idx] for idx in indices]\n",
        "\n",
        "        examples = sorted(examples, key=lambda e: len(e[0]), reverse=True)\n",
        "        src_sents = [e[0] for e in examples]\n",
        "        tgt_sents = [e[1] for e in examples]\n",
        "\n",
        "        yield src_sents, tgt_sents"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGIm-Vo8mWot"
      },
      "source": [
        "def evaluate_ppl(model, val_data, batch_size=32):\n",
        "    \"\"\" Evaluate perplexity on dev sentences\n",
        "    :param model: NMT Model\n",
        "    :type model: NMT\n",
        "    :param dev_data: list of tuples containing source and target sentence.\n",
        "        i.e. (list of (src_sent, tgt_sent))\n",
        "    :param val_data: List[Tuple[List[str], List[str]]]\n",
        "    :param batch_size: size of batches to extract\n",
        "    :type batch_size: int\n",
        "    :returns ppl: perplexity on val sentences\n",
        "    \"\"\"\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "\n",
        "    cum_loss = 0.\n",
        "    cum_tgt_words = 0.\n",
        "\n",
        "    # no_grad() signals backend to throw away all gradients\n",
        "    with torch.no_grad():\n",
        "        for src_sents, tgt_sents in batch_iter(val_data, batch_size):\n",
        "            loss = -model(src_sents, tgt_sents).sum()\n",
        "\n",
        "            cum_loss += loss.item()\n",
        "            tgt_word_num_to_predict = sum(len(s[1:]) for s in tgt_sents)  # omitting leading `<s>`\n",
        "            cum_tgt_words += tgt_word_num_to_predict\n",
        "\n",
        "        ppl = np.exp(cum_loss / cum_tgt_words)\n",
        "\n",
        "    if was_training:\n",
        "        model.train()\n",
        "\n",
        "    return ppl\n",
        "\n",
        "\n",
        "def compute_corpus_level_bleu_score(references: List[List[str]], hypotheses: List[Hypothesis]) -> float:\n",
        "    \"\"\" Given decoding results and reference sentences, compute corpus-level BLEU score.\n",
        "    :param references: a list of gold-standard reference target sentences\n",
        "    :type references: List[List[str]]\n",
        "    :param hypotheses: a list of hypotheses, one for each reference\n",
        "    :type hypotheses: List[Hypothesis]\n",
        "    :returns bleu_score: corpus-level BLEU score\n",
        "    \"\"\"\n",
        "    if references[0][0] == '<s>':\n",
        "        references = [ref[1:-1] for ref in references]\n",
        "    bleu_score = corpus_bleu([[ref] for ref in references],\n",
        "                             [hyp.value for hyp in hypotheses])\n",
        "    return bleu_score\n",
        "\n",
        "\n",
        "def evaluate_bleu(references, model, source):\n",
        "    \"\"\"Generate decoding results and compute BLEU score.\n",
        "    :param model: NMT Model\n",
        "    :type model: NMT\n",
        "    :param references: a list of gold-standard reference target sentences\n",
        "    :type references: List[List[str]]\n",
        "    :param source: a list of source sentences\n",
        "    :type source: List[List[str]]\n",
        "    :returns bleu_score: corpus-level BLEU score\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        top_hypotheses = []\n",
        "        for s in tqdm(source, leave=False):\n",
        "            hyps = model.beam_search(s, beam_size=16, max_decoding_time_step=(len(s)+10))\n",
        "            top_hypotheses.append(hyps[0])\n",
        "    \n",
        "    s1 = compute_corpus_level_bleu_score(references, top_hypotheses)\n",
        "    \n",
        "    return s1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSq1z1L7lumv"
      },
      "source": [
        "def train_and_evaluate(model, train_data, val_data, optimizer, epochs=10, train_batch_size=32, clip_grad=2, log_every = 100, valid_niter = 500, model_save_path=\"NMT_model.ckpt\"):\n",
        "    num_trail = 0\n",
        "    cum_examples = report_examples = epoch = valid_num = 0\n",
        "    hist_valid_scores = []\n",
        "    train_iter = patience = cum_loss = report_loss = cum_tgt_words = report_tgt_words = 0\n",
        "\n",
        "    print('Begin Maximum Likelihood training')\n",
        "    train_time = begin_time = time.time()\n",
        "\n",
        "    val_data_tgt = [tgt for _, tgt in val_data]\n",
        "    val_data_src = [src for src, _ in val_data]\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        for src_sents, tgt_sents in batch_iter(train_data, batch_size=train_batch_size, shuffle=True):\n",
        "            train_iter += 1\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            batch_size = len(src_sents)\n",
        "            \n",
        "            example_losses = -model(src_sents, tgt_sents)\n",
        "            batch_loss = example_losses.sum()\n",
        "            loss = batch_loss / batch_size\n",
        "            loss.backward()\n",
        "            \n",
        "            # clip gradient\n",
        "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
        "            \n",
        "            optimizer.step()\n",
        "            \n",
        "            batch_losses_val = batch_loss.item()\n",
        "            report_loss += batch_losses_val\n",
        "            cum_loss += batch_losses_val\n",
        "            \n",
        "            tgt_words_num_to_predict = sum(len(s[1:]) for s in tgt_sents)  # omitting leading `<s>`\n",
        "            report_tgt_words += tgt_words_num_to_predict\n",
        "            cum_tgt_words += tgt_words_num_to_predict\n",
        "            report_examples += batch_size\n",
        "            cum_examples += batch_size\n",
        "\n",
        "            if train_iter % log_every == 0:\n",
        "                print('epoch %d, iter %d, avg. loss %.2f, avg. ppl %.2f ' \\\n",
        "                        'cum. examples %d, speed %.2f words/sec, time elapsed %.2f sec' % (epoch, train_iter,\n",
        "                                                                                            report_loss / report_examples,\n",
        "                                                                                            math.exp(report_loss / report_tgt_words),\n",
        "                                                                                            cum_examples,\n",
        "                                                                                            report_tgt_words / (time.time() - train_time),\n",
        "                                                                                            time.time() - begin_time))\n",
        "                train_time = time.time()\n",
        "                report_loss = report_tgt_words = report_examples = 0.\n",
        "\n",
        "                \n",
        "\n",
        "            # perform validation\n",
        "            if train_iter % valid_niter == 0:\n",
        "                print('epoch %d, iter %d, cum. loss %.2f, cum. ppl %.2f cum. examples %d' % (epoch, train_iter,\n",
        "                                                                                            cum_loss / cum_examples,\n",
        "                                                                                            np.exp(cum_loss / cum_tgt_words),\n",
        "                                                                                            cum_examples))\n",
        "                \n",
        "                cum_loss = cum_examples = cum_tgt_words = 0.\n",
        "                valid_num += 1\n",
        "\n",
        "                print('begin validation ...')\n",
        "\n",
        "                # compute dev. ppl and bleu\n",
        "                dev_ppl = evaluate_ppl(model, val_data, batch_size=128)   # dev batch size can be a bit larger\n",
        "                valid_metric = -dev_ppl\n",
        "                \n",
        "                bleu_score = evaluate_bleu(val_data_tgt, model, val_data_src)*100\n",
        "\n",
        "                print('validation: iter %d, dev. ppl %f, bleu_score %f' % (train_iter, dev_ppl, bleu_score))\n",
        "\n",
        "                is_better = len(hist_valid_scores) == 0 or valid_metric > max(hist_valid_scores)\n",
        "                hist_valid_scores.append(bleu_score)\n",
        "\n",
        "                if is_better:\n",
        "                    print('save currently the best model to [%s]' % model_save_path)\n",
        "                    model.save(model_save_path)\n",
        "\n",
        "                    # also save the optimizers' state\n",
        "                    torch.save(optimizer.state_dict(), model_save_path + '.optim')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ShIVo6llLvy",
        "outputId": "13d04d3e-1bcc-4d25-b7f5-4d2651ece8be"
      },
      "source": [
        "embed_size = 128\n",
        "hidden_size = 512\n",
        "src_vocab = src\n",
        "tgt_vocab = tgt\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2aRBV96RcGe"
      },
      "source": [
        "epochs = 30\n",
        "\n",
        "# epochs = 10\n",
        "train_batch_size = 16\n",
        "clip_grad = 2\n",
        "log_every = 100\n",
        "valid_niter = 2000\n",
        "model_save_path=\"NMT_model.ckpt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pBNYqULlVDJ"
      },
      "source": [
        "model = NMT(\n",
        "    embed_size,\n",
        "    hidden_size,\n",
        "    src_vocab,\n",
        "    tgt_vocab,\n",
        "    device=device,\n",
        "    pretrained_source=None,\n",
        "    pretrained_target=None,\n",
        ")\n",
        "model.to(device)\n",
        "model.train()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aThwLkrr2-gi"
      },
      "source": [
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 873,
          "referenced_widgets": [
            "342093a131cb4741a2bb915e2e8f5128",
            ""
          ]
        },
        "id": "I11DvY80odkg",
        "outputId": "eda73b4e-8db7-433d-cf8d-d1636367d2d7"
      },
      "source": [
        "\n",
        "train_and_evaluate(\n",
        "    model,\n",
        "    train_data,\n",
        "    val_data,\n",
        "    optimizer,\n",
        "    epochs,\n",
        "    train_batch_size,\n",
        "    clip_grad,\n",
        "    log_every,\n",
        "    valid_niter,\n",
        "    model_save_path\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Begin Maximum Likelihood training\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "342093a131cb4741a2bb915e2e8f5128",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0, iter 100, avg. loss 89.47, avg. ppl 511.12 cum. examples 1600, speed 5061.64 words/sec, time elapsed 4.53 sec\n",
            "epoch 0, iter 200, avg. loss 80.78, avg. ppl 285.12 cum. examples 3200, speed 5435.52 words/sec, time elapsed 8.74 sec\n",
            "epoch 0, iter 300, avg. loss 75.71, avg. ppl 221.68 cum. examples 4800, speed 4719.71 words/sec, time elapsed 13.49 sec\n",
            "epoch 0, iter 400, avg. loss 71.31, avg. ppl 178.76 cum. examples 6400, speed 5276.62 words/sec, time elapsed 17.66 sec\n",
            "epoch 0, iter 500, avg. loss 70.28, avg. ppl 164.15 cum. examples 8000, speed 5051.50 words/sec, time elapsed 22.03 sec\n",
            "epoch 0, iter 600, avg. loss 70.45, avg. ppl 144.35 cum. examples 9600, speed 5470.58 words/sec, time elapsed 26.17 sec\n",
            "epoch 0, iter 700, avg. loss 71.27, avg. ppl 139.91 cum. examples 11200, speed 4809.56 words/sec, time elapsed 30.97 sec\n",
            "epoch 0, iter 800, avg. loss 64.85, avg. ppl 119.21 cum. examples 12800, speed 4960.40 words/sec, time elapsed 35.34 sec\n",
            "epoch 0, iter 900, avg. loss 62.98, avg. ppl 112.41 cum. examples 14400, speed 5133.47 words/sec, time elapsed 39.50 sec\n",
            "epoch 0, iter 1000, avg. loss 63.75, avg. ppl 109.89 cum. examples 16000, speed 5608.59 words/sec, time elapsed 43.37 sec\n",
            "epoch 0, iter 1100, avg. loss 61.70, avg. ppl 103.78 cum. examples 17600, speed 4579.29 words/sec, time elapsed 48.02 sec\n",
            "epoch 0, iter 1200, avg. loss 63.31, avg. ppl 104.08 cum. examples 19200, speed 4727.66 words/sec, time elapsed 52.63 sec\n",
            "epoch 0, iter 1300, avg. loss 62.46, avg. ppl 94.68 cum. examples 20800, speed 5317.57 words/sec, time elapsed 56.76 sec\n",
            "epoch 0, iter 1400, avg. loss 63.46, avg. ppl 93.41 cum. examples 22400, speed 5342.88 words/sec, time elapsed 60.95 sec\n",
            "epoch 0, iter 1500, avg. loss 63.61, avg. ppl 94.33 cum. examples 24000, speed 4926.02 words/sec, time elapsed 65.50 sec\n",
            "epoch 0, iter 1600, avg. loss 63.13, avg. ppl 88.12 cum. examples 25600, speed 5003.42 words/sec, time elapsed 70.00 sec\n",
            "epoch 0, iter 1700, avg. loss 60.26, avg. ppl 83.22 cum. examples 27200, speed 4353.34 words/sec, time elapsed 75.01 sec\n",
            "epoch 0, iter 1800, avg. loss 62.11, avg. ppl 83.37 cum. examples 28800, speed 5799.71 words/sec, time elapsed 78.89 sec\n",
            "epoch 0, iter 1900, avg. loss 62.07, avg. ppl 84.33 cum. examples 30400, speed 4752.46 words/sec, time elapsed 83.60 sec\n",
            "epoch 0, iter 2000, avg. loss 62.61, avg. ppl 81.31 cum. examples 32000, speed 5588.84 words/sec, time elapsed 87.67 sec\n",
            "epoch 0, iter 2000, cum. loss 67.28, cum. ppl 126.80 cum. examples 32000\n",
            "begin validation ...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1837 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "validation: iter 2000, dev. ppl 78.598888, bleu_score 2.090935\n",
            "save currently the best model to [NMT_model.ckpt]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "save model parameters to [NMT_model.ckpt]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0, iter 2100, avg. loss 61.01, avg. ppl 77.83 cum. examples 1600, speed 337.63 words/sec, time elapsed 154.07 sec\n",
            "epoch 0, iter 2200, avg. loss 60.86, avg. ppl 72.47 cum. examples 3200, speed 4957.04 words/sec, time elapsed 158.66 sec\n",
            "epoch 0, iter 2300, avg. loss 60.48, avg. ppl 73.97 cum. examples 4800, speed 4771.24 words/sec, time elapsed 163.37 sec\n",
            "epoch 1, iter 2400, avg. loss 58.56, avg. ppl 67.54 cum. examples 6387, speed 5784.34 words/sec, time elapsed 167.19 sec\n",
            "epoch 1, iter 2500, avg. loss 55.79, avg. ppl 56.62 cum. examples 7987, speed 4700.58 words/sec, time elapsed 171.89 sec\n",
            "epoch 1, iter 2600, avg. loss 59.23, avg. ppl 59.19 cum. examples 9587, speed 5480.93 words/sec, time elapsed 176.13 sec\n",
            "epoch 1, iter 2700, avg. loss 56.81, avg. ppl 57.61 cum. examples 11187, speed 4245.62 words/sec, time elapsed 181.41 sec\n",
            "epoch 1, iter 2800, avg. loss 52.87, avg. ppl 52.42 cum. examples 12787, speed 5617.16 words/sec, time elapsed 185.21 sec\n",
            "epoch 1, iter 2900, avg. loss 56.88, avg. ppl 57.38 cum. examples 14387, speed 4754.86 words/sec, time elapsed 189.94 sec\n",
            "epoch 1, iter 3000, avg. loss 54.58, avg. ppl 52.44 cum. examples 15987, speed 5484.88 words/sec, time elapsed 193.96 sec\n",
            "epoch 1, iter 3100, avg. loss 55.75, avg. ppl 55.71 cum. examples 17587, speed 5082.66 words/sec, time elapsed 198.33 sec\n",
            "epoch 1, iter 3200, avg. loss 60.35, avg. ppl 57.85 cum. examples 19187, speed 5223.04 words/sec, time elapsed 202.88 sec\n",
            "epoch 1, iter 3300, avg. loss 51.94, avg. ppl 48.70 cum. examples 20787, speed 4523.46 words/sec, time elapsed 207.61 sec\n",
            "epoch 1, iter 3400, avg. loss 55.41, avg. ppl 52.18 cum. examples 22387, speed 5676.72 words/sec, time elapsed 211.56 sec\n",
            "epoch 1, iter 3500, avg. loss 53.39, avg. ppl 49.00 cum. examples 23987, speed 5107.73 words/sec, time elapsed 215.86 sec\n",
            "epoch 1, iter 3600, avg. loss 54.36, avg. ppl 49.48 cum. examples 25587, speed 4901.43 words/sec, time elapsed 220.41 sec\n",
            "epoch 1, iter 3700, avg. loss 53.34, avg. ppl 48.38 cum. examples 27187, speed 4458.61 words/sec, time elapsed 225.34 sec\n",
            "epoch 1, iter 3800, avg. loss 53.38, avg. ppl 49.48 cum. examples 28787, speed 5830.39 words/sec, time elapsed 229.10 sec\n",
            "epoch 1, iter 3900, avg. loss 54.18, avg. ppl 48.79 cum. examples 30387, speed 5053.31 words/sec, time elapsed 233.51 sec\n",
            "epoch 1, iter 4000, avg. loss 51.20, avg. ppl 44.34 cum. examples 31987, speed 5331.66 words/sec, time elapsed 237.56 sec\n",
            "epoch 1, iter 4000, cum. loss 56.02, cum. ppl 55.98 cum. examples 31987\n",
            "begin validation ...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1837 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "validation: iter 4000, dev. ppl 53.742877, bleu_score 3.253782\n",
            "epoch 1, iter 4100, avg. loss 54.71, avg. ppl 49.81 cum. examples 1600, speed 342.95 words/sec, time elapsed 302.88 sec\n",
            "epoch 1, iter 4200, avg. loss 53.42, avg. ppl 46.09 cum. examples 3200, speed 5302.14 words/sec, time elapsed 307.08 sec\n",
            "epoch 1, iter 4300, avg. loss 53.19, avg. ppl 45.95 cum. examples 4800, speed 4524.27 words/sec, time elapsed 312.00 sec\n",
            "epoch 1, iter 4400, avg. loss 54.31, avg. ppl 46.00 cum. examples 6400, speed 5555.04 words/sec, time elapsed 316.08 sec\n",
            "epoch 1, iter 4500, avg. loss 50.94, avg. ppl 43.42 cum. examples 8000, speed 4850.83 words/sec, time elapsed 320.54 sec\n",
            "epoch 1, iter 4600, avg. loss 53.79, avg. ppl 45.86 cum. examples 9600, speed 5409.40 words/sec, time elapsed 324.70 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCmNnAmScmI5"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "# with open('/content/gdrive/My Drive/sophomore/nlp 4740/project_3/NMT_statedict.ckpt', 'w') as f:\n",
        "#   f.write('NMT_statedict.ckpt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLHafe0WqOAf"
      },
      "source": [
        "# torch.save(model.state_dict, 'NMT_statedict.ckpt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJqQTVxdZjQ3"
      },
      "source": [
        "# Part 2: Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Of6kWAcfgde"
      },
      "source": [
        "## Part 2.1: Within-model comparison: ablation study\n",
        "We train 4 variants of the RNN model:\n",
        "\n",
        "1. Baseline model\n",
        "2. Baseline model made more complex by modification $A$ (e.g. changing the hidden dimensionality from $h$ to $2h$).\n",
        "3. Baseline model made more complex by modification $B$ (where $B$ is an entirely distinct/different update from $A$).\n",
        "4. Baseline model with both modifications $A$ and $B$ applied.\n",
        "\n",
        "Under the framing of an ablation study, we would describe this as beginning with model 4 and then ablating (i.e. removing) each of the two modifications, in turn; and then removing both to see if they were genuinely neccessary for the performance we observed. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwKsMKaU2X0P"
      },
      "source": [
        "import re\n",
        "def untokenize(words):\n",
        "    \"\"\"\n",
        "    Untokenizing a text undoes the tokenizing operation, restoring\n",
        "    punctuation and spaces to the places that people expect them to be.\n",
        "    Ideally, `untokenize(tokenize(text))` should be identical to `text`,\n",
        "    except for line breaks.\n",
        "    \"\"\"\n",
        "    text = ' '.join(words)\n",
        "    step1 = text.replace(\"`` \", '\"').replace(\" ''\", '\"').replace('. . .',  '...')\n",
        "    step2 = step1.replace(\" ( \", \" (\").replace(\" ) \", \") \")\n",
        "    step3 = re.sub(r' ([.,:;?!%]+)([ \\'\"`])', r\"\\1\\2\", step2)\n",
        "    step4 = re.sub(r' ([.,:;?!%]+)$', r\"\\1\", step3)\n",
        "    step5 = step4.replace(\" '\", \"'\").replace(\" n't\", \"n't\").replace(\n",
        "         \"can not\", \"cannot\")\n",
        "    step6 = step5.replace(\" ` \", \" '\")\n",
        "    return step6.strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TULtij8lzQpt"
      },
      "source": [
        "### 2.1.1 Configuration 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBoo8VMeD103"
      },
      "source": [
        "# baseline_nmt = NMT()\n",
        "model = NMT(\n",
        "    embed_size,\n",
        "    hidden_size,\n",
        "    src_vocab,\n",
        "    tgt_vocab,\n",
        "    device=device,\n",
        "    pretrained_source=None,\n",
        "    pretrained_target=None,\n",
        ")\n",
        "model.to(device)\n",
        "model.train()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "train_and_evaluate(\n",
        "    model,\n",
        "    train_data,\n",
        "    val_data,\n",
        "    optimizer,\n",
        "    epochs,\n",
        "    train_batch_size,\n",
        "    clip_grad,\n",
        "    log_every,\n",
        "    valid_niter,\n",
        "    model_save_path\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2Q4LpZOzxa6"
      },
      "source": [
        "### 2.1.2 Configuration 2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSE9bbSnGI2A"
      },
      "source": [
        "# mod_a_nmt = NMT()\n",
        "# modification A\n",
        "model = NMT(\n",
        "    embed_size,\n",
        "    2*hidden_size,\n",
        "    src_vocab,\n",
        "    tgt_vocab,\n",
        "    device=device,\n",
        "    pretrained_source=None,\n",
        "    pretrained_target=None,\n",
        ")\n",
        "model.to(device)\n",
        "model.train()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "model_save_path = \"NMT_modelA.ckpt\"\n",
        "train_and_evaluate(\n",
        "    model,\n",
        "    train_data,\n",
        "    val_data,\n",
        "    optimizer,\n",
        "    epochs,\n",
        "    train_batch_size,\n",
        "    clip_grad,\n",
        "    log_every,\n",
        "    valid_niter,\n",
        "    model_save_path\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVG-Pqa9z60-"
      },
      "source": [
        "### 2.1.3 Configuration 3\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WsI_BPpGJ5r"
      },
      "source": [
        "# mod_b_nmt = NMT()\n",
        "# modification B\n",
        "model = NMT(\n",
        "    2*embed_size,\n",
        "    hidden_size,\n",
        "    src_vocab,\n",
        "    tgt_vocab,\n",
        "    device=device,\n",
        "    pretrained_source=None,\n",
        "    pretrained_target=None,\n",
        ")\n",
        "model.to(device)\n",
        "model.train()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "model_save_path = \"NMT_modelB.ckpt\"\n",
        "train_and_evaluate(\n",
        "    model,\n",
        "    train_data,\n",
        "    val_data,\n",
        "    optimizer,\n",
        "    epochs,\n",
        "    train_batch_size,\n",
        "    clip_grad,\n",
        "    log_every,\n",
        "    valid_niter,\n",
        "    model_save_path\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfukYWxcz-Za"
      },
      "source": [
        "### 2.1.4 Configuration 4\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbwLS9lEGLJU"
      },
      "source": [
        "# both_mod_nmt = NMT()\n",
        "# modification A&B\n",
        "model = NMT(\n",
        "    2*embed_size,\n",
        "    2*hidden_size,\n",
        "    src_vocab,\n",
        "    tgt_vocab,\n",
        "    device=device,\n",
        "    pretrained_source=None,\n",
        "    pretrained_target=None,\n",
        ")\n",
        "model.to(device)\n",
        "model.train()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "model_save_path = \"NMT_modelAB.ckpt\"\n",
        "train_and_evaluate(\n",
        "    model,\n",
        "    train_data,\n",
        "    val_data,\n",
        "    optimizer,\n",
        "    epochs,\n",
        "    train_batch_size,\n",
        "    clip_grad,\n",
        "    log_every,\n",
        "    valid_niter,\n",
        "    model_save_path\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CiPPaO-0Dmy"
      },
      "source": [
        "### 2.1.5 Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3VY-ick3oMu"
      },
      "source": [
        "model = NMT.load(\"drive/My Drive/sophomore/nlp 4740/p3/NMT_model.ckpt\")\n",
        "modelA = NMT.load(\"drive/My Drive/sophomore/nlp 4740/p3/NMT_modelA.ckpt\")\n",
        "modelB = NMT.load(\"drive/My Drive/sophomore/nlp 4740/p3/NMT_modelB.ckpt\")\n",
        "modelAB = NMT.load(\"drive/My Drive/sophomore/nlp 4740/p3/NMT_modelAB.ckpt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_D9cmQ_5b_f"
      },
      "source": [
        "def evaluate_without_saving(model, train_data, val_data, epochs=10, train_batch_size=32, clip_grad=2, log_every = 100, valid_niter = 500):\n",
        "\n",
        "  print('begin validation ...')\n",
        "\n",
        "  # compute dev. ppl and bleu\n",
        "  dev_ppl = evaluate_ppl(model, val_data, batch_size=128)   # dev batch size can be a bit larger\n",
        "  valid_metric = -dev_ppl\n",
        "  \n",
        "  bleu_score = evaluate_bleu(val_data_tgt, model, val_data_src)*100\n",
        "\n",
        "  print(\"ppl\", dev_ppl)\n",
        "  print(\"bleu\", bleu_score)\n",
        "  print('validation: dev. ppl %f, bleu_score %f' % (dev_ppl, bleu_score))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "be961aa5a37e41d7957c67830c4096cf",
            "54281bbd507a44ddac92d6ae46c4ae39",
            "37dadd0a03f4488bbddd23e393b17684",
            "d70a7220fc464aa09e13f596d861b63c",
            "4401795f1ec9493b8a0550bfb7cd8a3e",
            "a9a7af43a4694a439f2921911a9bd11a",
            "bc5919d199504ccd93f80f5631b4b5f8",
            "60fd2f6f238e4a38a562bdf40c0a6233",
            "7952b4eadd6c4a929c8aa77c197cc09c",
            "86789ef50c9148d89361c61ac902f7cc",
            "bd2bdaaa29ba4505883b000a19f13bf5"
          ]
        },
        "id": "LupkDqJQ6YAo",
        "outputId": "9d43aa14-7360-4976-ce40-b7e4609441b0"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "model.to(device)\n",
        "evaluate_without_saving(\n",
        "    model,\n",
        "    train_data,\n",
        "    val_data,\n",
        "    epochs,\n",
        "    train_batch_size,\n",
        "    clip_grad,\n",
        "    log_every\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "begin validation ...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be961aa5a37e41d7957c67830c4096cf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1837 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ppl 78.56417308463188\n",
            "bleu 2.0913877188792505\n",
            "validation: dev. ppl 78.564173, bleu_score 2.091388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "77d54c6a517b4c7abe2ee25ac1455c3b",
            "5c796872b221446abfc160d08466a626",
            "a7d5ee3d9f78432b8b8093a9c18561ab",
            "61b1a72d179c487aa28a76f218fb7642",
            "2e100923ce444f49ada4321c1f43723a",
            "f4c6fc0453f9414f9bc78c8ba5bf374a",
            "a42bcd8c70714317b49fc076c2eff2f0",
            "f8eb7d07fa7f4dc1a2481144c653e9d7",
            "c8efdc799b1f4f65b205d09195ff0a20",
            "f18fdc7c6ade414c8d8fa7675f9c480a",
            "fb63a4f35c1f4de4b1b8701ea732cf03"
          ]
        },
        "id": "s59ilpJBANN4",
        "outputId": "0cd8186d-dcda-4355-ab29-131766a33f04"
      },
      "source": [
        "modelA.to(device)\n",
        "evaluate_without_saving(\n",
        "    modelA,\n",
        "    train_data,\n",
        "    val_data,\n",
        "    epochs,\n",
        "    train_batch_size,\n",
        "    clip_grad,\n",
        "    log_every\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "begin validation ...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77d54c6a517b4c7abe2ee25ac1455c3b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1837 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ppl 75.04400906886652\n",
            "bleu 2.3700046036300892\n",
            "validation: dev. ppl 75.044009, bleu_score 2.370005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "66a6fda0f5924814b10d757fe116c3bc"
          ]
        },
        "id": "MmK6Xd9eATlV",
        "outputId": "208ef689-aab5-401d-aa8a-6c12ece3fd22"
      },
      "source": [
        "modelB.to(device)\n",
        "evaluate_without_saving(\n",
        "    modelB,\n",
        "    train_data,\n",
        "    val_data,\n",
        "    epochs,\n",
        "    train_batch_size,\n",
        "    clip_grad,\n",
        "    log_every\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "begin validation ...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "66a6fda0f5924814b10d757fe116c3bc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1837 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ppl 70.19409542425542\n",
            "bleu 2.56449775292072\n",
            "validation: dev. ppl 70.194095, bleu_score 2.564498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "ffa4058550624e6fb602bc51b85ebcac"
          ]
        },
        "id": "IkdjlfXSAVb6",
        "outputId": "dfc6019e-1300-4753-df11-45eb4f0952c0"
      },
      "source": [
        "modelAB.to(device)\n",
        "evaluate_without_saving(\n",
        "    modelAB,\n",
        "    train_data,\n",
        "    val_data,\n",
        "    epochs,\n",
        "    train_batch_size,\n",
        "    clip_grad,\n",
        "    log_every\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "begin validation ...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ffa4058550624e6fb602bc51b85ebcac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1837 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ppl 74.08051914103658\n",
            "bleu 1.9298960568563488\n",
            "validation: dev. ppl 74.080519, bleu_score 1.929896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81c2YMpY3MYH"
      },
      "source": [
        "### Nuanced Study: Sentence lengths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xqy0HKPhk5Tt"
      },
      "source": [
        "def evaluate_long_sentences(model, val_data, val_data_src, val_data_tgt, train_batch_size=32):\n",
        "\n",
        "  # print('begin validation ...')\n",
        "\n",
        "  # compute dev. ppl and bleu\n",
        "  dev_ppl = evaluate_ppl(model, val_data, batch_size=2)   # dev batch size can be a bit larger\n",
        "  valid_metric = -dev_ppl\n",
        "  \n",
        "  bleu_score = evaluate_bleu(val_data_tgt, model, val_data_src)*100\n",
        "\n",
        "  # print(\"ppl\", dev_ppl)\n",
        "  # print(\"bleu\", bleu_score)\n",
        "  print('validation: dev. ppl %f, bleu_score %f' % (dev_ppl, bleu_score))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azb7Oz-xkeSY"
      },
      "source": [
        "long_sentences = val_data.copy()\n",
        "for source, target in val_data:\n",
        "  if len(source) <= 45: \n",
        "    long_sentences.remove((source, target))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_3PmN4hksDs",
        "outputId": "b6769801-0d42-4229-85ce-a6731731eb7b"
      },
      "source": [
        "len(long_sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KklKttnUmx9t"
      },
      "source": [
        "long_target = val_data_tgt.copy()\n",
        "long_source = val_data_src.copy()\n",
        "for source, target in val_data:\n",
        "  if len(source) <= 45:\n",
        "    long_source.remove(source)\n",
        "    long_target.remove(target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357,
          "referenced_widgets": [
            "642ed50d610a46518132d1d81d8eff72",
            "d37ef297ff054874a96a8dee6dbb05a1",
            "2fb5c4a8522b4e2a9dc2370469591db1",
            "9e3da17532ef48b7a6e18b4e33dc57fc",
            "e21ea51fdff948f0acd1f8b7ca19a40c",
            "4a507a958dd94955a55316c6874590d0",
            "6ebf02ed6cb74d4db2840b782fa08498",
            "f5843682c43a4b478e667c8bef9a967a",
            "4f0dd45dfbf34c64aa9c1bfe4003efc5",
            "2b67a668714840828f5dcbc8bd0f9ca7",
            "e27e709353c1498e925f3bc9324ee0bc",
            "7604afa227b54cf4aa88115f88992f79",
            "0c973d1a1c474f2788a9c5887530c8eb",
            "7b1d9f9ca96f4dc3bab5cd0d1fe8dd26",
            "52fd6ffcf70f46afb9f0171dff0eeeb9",
            "32dc601f50ed4cd9908d80baac1cdc88",
            "b97bc1ed31794b8f86da558d38554f4f",
            "066c3e834b3f47e08d4123091dd4d0bc",
            "4938814d983a4e47bb26d9e5956c90fc",
            "8550e49f730d490db06dbfecbbfaf6d3",
            "b7cd55c5b6974d2d80a14edc635bbd3c",
            "0415c69f92ac40b6887c850214b631c6",
            "28be69da316145cc997fb88669c3835c",
            "40bd6d2efa8f4be38178c96a11fbb31b",
            "6552a71c617c4bb4afe1c180d35ca6fa",
            "c1de9d199dec4d938f2a9360591d4f3f",
            "b6c6fcba7f964c0aa3e27b53e15b1a99",
            "3a583d6b4de04d74bd42d2a813f32d35",
            "39c8b77e176b450a819c476fba6d546c",
            "63861a3775a94afbada3983f9ef4820d",
            "8317e90ef6f64033bec8ed7df8d232ba",
            "b6896318a3b7479cb0d285e38399b001",
            "92ab7785d9d64895b8c117be09b574b0",
            "412d4441f0b34d0a982235f958fcdb9f",
            "603e57e04d78422daef459c457838e50",
            "4d824368aa75494eaca36bda6dcf0a26",
            "5265f531e9f94b5082c9cbd78523b5b1",
            "72a87bd11f734b0ca46aa812f738757d",
            "1e1f41dcd4ad433aabf6eb761916adab",
            "b6b2a422df72417fb823140e4441b98b",
            "fc0551a31c844b1c8ca389c6211db0a3",
            "d48fafabc9c34a1da1e522492bc0797f",
            "27ba842903f7433badec4c35122cb303",
            "afed3623abad420fa6e7f7ccbd5325e8"
          ]
        },
        "id": "X8JMOXxOkzbP",
        "outputId": "f324e95b-c278-424c-93af-0f0b044baf18"
      },
      "source": [
        "evaluate_long_sentences(model, long_sentences, long_source, long_target, train_batch_size,)\n",
        "evaluate_long_sentences(modelA, long_sentences, long_source, long_target, train_batch_size,)\n",
        "evaluate_long_sentences(modelB, long_sentences, long_source, long_target, train_batch_size,)\n",
        "evaluate_long_sentences(modelAB, long_sentences, long_source, long_target, train_batch_size,)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "begin validation ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "642ed50d610a46518132d1d81d8eff72",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/26 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ppl 184.10522420037125\n",
            "bleu 7.143017268331987\n",
            "validation: dev. ppl 184.105224, bleu_score 7.143017\n",
            "begin validation ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7604afa227b54cf4aa88115f88992f79",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/26 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ppl 166.80338612522544\n",
            "bleu 1.6730970086739416\n",
            "validation: dev. ppl 166.803386, bleu_score 1.673097\n",
            "begin validation ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "28be69da316145cc997fb88669c3835c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/26 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ppl 158.61309483281323\n",
            "bleu 1.5272698739238728\n",
            "validation: dev. ppl 158.613095, bleu_score 1.527270\n",
            "begin validation ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "412d4441f0b34d0a982235f958fcdb9f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/26 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ppl 174.9625787267432\n",
            "bleu 1.6646726434427883\n",
            "validation: dev. ppl 174.962579, bleu_score 1.664673\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kt5m_x3qy0H",
        "outputId": "d74410c2-9c5c-460b-bd40-2bc899e32f28"
      },
      "source": [
        "threshold = 3\n",
        "short_sentences = val_data.copy()\n",
        "for source, target in val_data:\n",
        "  if len(source) > threshold: \n",
        "    short_sentences.remove((source, target))\n",
        "short_target = val_data_tgt.copy()\n",
        "short_source = val_data_src.copy()\n",
        "for source, target in val_data:\n",
        "  if len(source) > threshold:\n",
        "    short_source.remove(source)\n",
        "    short_target.remove(target)\n",
        "print(len(short_sentences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221,
          "referenced_widgets": [
            "e16f90ab738749a8b790a3f732afef14",
            "cb80f644cfaf4060abe9f9d2920c2e33",
            "24010b3a5aa8424a9b40cac353d973ba",
            "25810c12ce9240c993bc7eddf5eb7e35",
            "080bc356eb1546ae953a0245f7d98c86",
            "2bb0c17920f745d3b77a77ae83c3390d",
            "ae4fed0367fd46acb8d06cc4af5045d2",
            "2b5d39301aba4340a7d00df5d7934da1",
            "1e75b09f82e140acb1f2eeb64362fa65",
            "3e27ef03d617434fb2e2ceb4799cbd3e",
            "b0f308da72804ef5b494ba8bd228a61f",
            "803732ac85d7459cb094a044a01259ec",
            "444c1ef847c543d38cabc72f6c4c27c8",
            "beeb94d35cce4b30a6ed8f931e43a192",
            "168aaa61587242f0b9ff7e07f24651bc",
            "e394a56eea074149ac4edc187ab783fb",
            "33dfdb1556bf41e6b0f45fa1d269a6c2",
            "c9fc6df3fc7e4b94a6a99db5dcd9e40f",
            "9d1d02883dcc41d1a0bf8f473676cbb0",
            "1e25e0fbc5ca41268f64a0ee4faa579c",
            "75668de49e254e39b9056b78ab918cdd",
            "ef7bf07f4bbc44d09ef2fe822c9f0248",
            "4f904efb1cab480b9e922063bf139d46",
            "7d2df268c8c4473e92827cd29ab4ffb4",
            "6e5f95171ac44a6ab5e1e6a1230ea30d",
            "f51b5a46f6634cafa6351b9d3e13d2f1",
            "fbd4d6e318a442ecb37ff7d16d997ec5",
            "3e3c7ee7e02f4ae190ce37455937c19f",
            "2784bc53e6c541b0943b6c7b888f9a03",
            "db794c4312274fc1ad4650aa06dd10b1",
            "fcd4971133764a9da013bef5904acfc3",
            "6cd76ad5153b433d97d4aeda33b68980",
            "0c173303ced34a84b18b72b34a6f3da9",
            "1e68eabc921641a0b68986018bac70e4",
            "e808669cbb1f4bf982b57ba75725690c",
            "69cb79e0ab3e48d599363405bcbf9603",
            "f9d1f8e99f4246c09a6845b01e812ac4",
            "2654f67bc9104f72ad6ba544b7dd6d3b",
            "4f0ed5e9bd044680afb053237174c9b7",
            "a2f7181465cc44fb81eeced33774dc09",
            "110e2f54d63f41389f370b7489d0b8a5",
            "68eaa371cf744e3aa29c3b120c60a18a",
            "4dfcf12d338646f29203cc76ae1e61a4",
            "e28bbe0153da47489bc89a2ecc4bab06"
          ]
        },
        "id": "ZHCeSz0ZrFhR",
        "outputId": "44b67077-4593-405a-d816-ea2f07a2de7e"
      },
      "source": [
        "evaluate_long_sentences(model, short_sentences, short_source, short_target, train_batch_size,)\n",
        "evaluate_long_sentences(modelA, short_sentences, short_source, short_target, train_batch_size,)\n",
        "evaluate_long_sentences(modelB, short_sentences, short_source, short_target, train_batch_size,)\n",
        "evaluate_long_sentences(modelAB, short_sentences, short_source, short_target, train_batch_size,)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e16f90ab738749a8b790a3f732afef14",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/118 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation: dev. ppl 15.761867, bleu_score 9.929016\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "803732ac85d7459cb094a044a01259ec",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/118 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation: dev. ppl 15.728714, bleu_score 9.954533\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f904efb1cab480b9e922063bf139d46",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/118 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation: dev. ppl 14.117991, bleu_score 12.572569\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e68eabc921641a0b68986018bac70e4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/118 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation: dev. ppl 18.048835, bleu_score 29.297609\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Z7EOyn9zDb_"
      },
      "source": [
        "\n",
        "**The 4 models:**\n",
        "\n",
        "Baseline: NMT with LSTM encoder and decoders, embed size of 256, hidden size of 1024. \n",
        "\n",
        "Ablation model A: Baseline model but reduced embed size to 128\n",
        "\n",
        "Ablation model B: Baseline model but reduced hidden size to 512\n",
        "\n",
        "Ablation model A+B: Baseline model but reduced embed size to 128 and reduced hidden size to 512.\n",
        "\n",
        "**Reasoning for the modifications:**\n",
        "\n",
        "In Q 1.6, I mentioned that embed size and hidden size both affect how well we can represent and retain our represented input. I concluded that big and small sizes have their separate advantages depending on the amount of training data we have and the complexity of the input. However, without empirical results, I could not state which size was the most suited size for this task. \n",
        "\n",
        "Running this ablation study would help us figure out whether our baseline model is needlessly complex (ex. If cutting embed or hidden size in half leads to similar performance, then we didn’t need that big of a size in the first place). If time permits, I would run an ablation study on the ablated models until we arrive at a reasonable performance-complexity tradeoff. \n",
        "\n",
        "**Report of Quantitative Scores (2 dp):**\n",
        "(in the order of\n",
        "Baseline,\n",
        "Ablation A,\n",
        "Ablation B,\n",
        "Ablation A+B)\n",
        "\n",
        "Perplexity:\n",
        "78.56\n",
        "75.04\n",
        "70.19\n",
        "74.08\n",
        "\n",
        "Bleu:\n",
        "2.09\n",
        "2.37\n",
        "2.56\n",
        "1.93\n",
        "\n",
        "**Nuanced Quantitative Analysis:**\n",
        "\n",
        "Before we dive in, let us first look at the scores to form intuition. Ablations A and B both individually lower the perplexity compared to the baseline while raising the bleu score. Metrics wise, this is an outright improvement, suggesting that the original model was too complex for the amount of data I had and training iterations I ran. \n",
        "Thus we arrive at our hypothesis: the original model is too complex and overfits / hasn’t converged yet\n",
        "\n",
        "Since the lack of convergence and overfitting is more evident in longer sentences (as the errors compound), if such a hypothesis were true, then the baseline should do the worst on long sentences, followed by ablations A and B, then the best should be ablation A+B (simplest model should generalize better if we don’t have enough data to converge). \n",
        "\n",
        "On the other hand, for short sentences the complexity should help more than the compounding errors hurt. Therefore we should expect to see the baseline do the best and ablations A and B follow, and A+B the worst. \n",
        "\n",
        "**Running on all sentences longer than 45 tokens we get:**\n",
        "(in order of \n",
        "Baseline\n",
        "Ablation A\n",
        "Ablation B\n",
        "Ablation A+B)\n",
        "\n",
        "Perplexity\n",
        "174.96\n",
        "166.80\n",
        "158.61\n",
        "184.11\n",
        "\n",
        "Bleu\n",
        "1.66\n",
        "1.67\n",
        "1.52\n",
        "7.14\n",
        "\n",
        "Indeed, the best is A+B, with a Bleu score over 4 times the others while maintaining similar perplexity! Ablations A and B both have lower perplexity than the baseline, and A has similar Bleu. \n",
        "\n",
        "**Running on all sentences shorter than 3 tokens we get: **\n",
        "(in order of \n",
        "Baseline\n",
        "Ablation A\n",
        "Ablation B\n",
        "Ablation A+B)\n",
        "\n",
        "Perplexity\n",
        "18.04\n",
        "14.11\n",
        "15.73\n",
        "15.76\n",
        "\n",
        "Bleu\n",
        "29.30\n",
        "9.95\n",
        "12.57\n",
        "9.92\n",
        "\n",
        "Indeed, the baseline has a 3 times higher Bleu score than the ablations, with similar perplexity. Note that ablation B seems to retain Bleu score better than ablation A. \n",
        "\n",
        "Since our results match our hypothesis, we can conclude that our evidence is correct: although the complexity of our baseline model significantly increases our ability to translate very short sentences, its complexity also leads to errors which compound over long sentences, causing its overall Bleu score to drop. \n",
        "\n",
        "If one were to choose 1 ablation, ablation B is the most effective ablation (doing similarly to A on long sentences, better than A and A+B on short sentences, and slightly better than A and A+B on average). I reckon this is because the hidden size acts as a bottleneck for the embeddings between the encoding and decoding parts, thus directly reducing this bottleneck’s size is more effective. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RhrCRDGwE73"
      },
      "source": [
        "# med_sentences = val_data.copy()\n",
        "# for source, target in val_data:\n",
        "#   if len(source) < 12 or len(source) > 15: \n",
        "#     med_sentences.remove((source, target))\n",
        "# med_target = val_data_tgt.copy()\n",
        "# med_source = val_data_src.copy()\n",
        "# for source, target in val_data:\n",
        "#   if len(source) < 12 or len(source) > 15: \n",
        "#     med_source.remove(source)\n",
        "#     med_target.remove(target)\n",
        "# print(len(med_sentences))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZc7-Z-cws2_"
      },
      "source": [
        "# evaluate_long_sentences(model, med_sentences, med_source, med_target, train_batch_size,)\n",
        "# evaluate_long_sentences(modelA, med_sentences, med_source, med_target, train_batch_size,)\n",
        "# evaluate_long_sentences(modelB, med_sentences, med_source, med_target, train_batch_size,)\n",
        "# evaluate_long_sentences(modelAB, med_sentences, med_source, med_target, train_batch_size,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nu4zL4nWnGB"
      },
      "source": [
        "# Live running demo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qO4HFGI92-5"
      },
      "source": [
        "#@title Translation\n",
        "#@markdown Enter a sentence to see the translation\n",
        "input_string = \"why should i play the roman fool and die on my own sword?\" #@param {type:\"string\"}\n",
        "model_type = \"baseline_nmt\" #@param [\"baseline_nmt\", \"mod_a_nmt\", \"mod_b_nmt\", \"both_mods_nmt\"]\n",
        "from IPython.display import HTML\n",
        "\n",
        "import re\n",
        "def untokenize(words):\n",
        "    \"\"\"\n",
        "    Untokenizing a text undoes the tokenizing operation, restoring\n",
        "    punctuation and spaces to the places that people expect them to be.\n",
        "    Ideally, `untokenize(tokenize(text))` should be identical to `text`,\n",
        "    except for line breaks.\n",
        "    \"\"\"\n",
        "    text = ' '.join(words)\n",
        "    step1 = text.replace(\"`` \", '\"').replace(\" ''\", '\"').replace('. . .',  '...')\n",
        "    step2 = step1.replace(\" ( \", \" (\").replace(\" ) \", \") \")\n",
        "    step3 = re.sub(r' ([.,:;?!%]+)([ \\'\"`])', r\"\\1\\2\", step2)\n",
        "    step4 = re.sub(r' ([.,:;?!%]+)$', r\"\\1\", step3)\n",
        "    step5 = step4.replace(\" '\", \"'\").replace(\" n't\", \"n't\").replace(\n",
        "         \"can not\", \"cannot\")\n",
        "    step6 = step5.replace(\" ` \", \" '\")\n",
        "    return step6.strip()\n",
        "\n",
        "output = \"\"\n",
        "\n",
        "# BAD THING TO DO BELOW!!\n",
        "model_used = globals()[model_type]\n",
        "\n",
        "with torch.no_grad():\n",
        "    # RUN MODEL\n",
        "    translation = untokenize(model.beam_search(input_string, beam_size=64, max_decoding_time_step=len(input_string)+10)[0].value)\n",
        "\n",
        "# Generate nice display\n",
        "output += '<p style=\"font-family:verdana; font-size:110%;\">'\n",
        "output += \" Input sequence: \"+input_string+\"</p>\"\n",
        "output += '<p style=\"font-family:verdana; font-size:110%;\">'\n",
        "output += f\" Translation to Shakespeare: {translation}</p><hr>\"\n",
        "output = \"<h3>Results:</h3>\" + output\n",
        "\n",
        "display(HTML(output))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}